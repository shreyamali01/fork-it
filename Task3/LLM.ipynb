{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Zero shot and Few shot Learning on ChatGroq models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API and Models \n",
    "Groq_Token = \"API_Key_here\"\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from llama3.1-8b: \n",
      "Based on the given data, I will analyze each data point and predict the activity.\n",
      "\n",
      "**Data Point 1:**\n",
      "1.  2.7574570e-001, -1.0371994e-002, -9.9775890e-002, -9.9837313e-001, -9.8693291e-001, -9.9102190e-001, -9.9866291e-001, -9.8713965e-001, -9.9108432e-001, -9.4376125e-001, -5.6428961e-001, -8.1432563e-001,  8.4975268e-001,  6.8922983e-001,  8.4737582e-001, -9.9110378e-001, -9.9999154e-001, -9.9983492e-001, -9.9973485e-001, -9.9859886e-001, -9.8980896e-001, -9.8928972e-001, -7.6858336e-001, -4.3323793e-001, -3.9328675e-001,  3.9409003e-001, -1.7537723e-001,  1.3718364e-001,  1.8434982e-001,  8.3437153e-002, -2.1274865e-002,  3.8584767e-002, -6.5816959e-002,  4.2912522e-001, -2.7979818e-001,  1.5752764e-001, -5.2535204e-002,  1.2899289e-002, -7.8381560e-002,  2.5741515e-001,  9.2417336e-001, -3.1759660e-001,  1.2458390e-001, -9.9800172e-001, -9.8939331e-001, -9.9196835e-001, -9.9791812e-001, -9.8990488e-001, -9.9261060e-001,  8.5020163e-001, -3.3207944e-001,  1.1805617e-001,  9.4442809e-001, -2.8847057e-001,  1.2594389e-001,  5.3761724e-002,  7.9725941e-001, -8.2692917e-001, -9.7200939e-001, -9.9787221e-001, -9.9142466e-001, -9.9400663e-001, -1.0000000e+000, -1.0000000e+000, -7.8618011e-001, -4.4300790e-001,  4.6643649e-001, -4.8988673e-001,  5.1345808e-001, -2.7782560e-001,  2.0762595e-001, -1.8315639e-001,  1.7982801e-001, -3.2368703e-001,  3.3180210e-001, -3.3983222e-001,  3.4544263e-001, -7.8945759e-001, -7.1051977e-001,  9.8382509e-001,  7.7145726e-002,  1.8711721e-002,  1.1466155e-002, -9.9636877e-001, -9.9148028e-001, -9.9279344e-001, -9.9610539e-001, -9.8879884e-001, -9.8980846e-001, -9.9435966e-001, -9.9784205e-001, -9.9586157e-001,  9.9728549e-001,  9.9351841e-001,  9.9619136e-001, -9.9392766e-001, -9.9996864e-001, -9.9988165e-001, -9.9986763e-001, -9.9368582e-001, -9.8495078e-001, -9.8172573e-001, -8.3927424e-001, -7.7938980e-001, -7.7317959e-001,  3.2097169e-001,  1.2056967e-001,  2.8412716e-001,  2.1790389e-001,  1.0240066e-001,  1.8176848e-001,  1.7987603e-001,  2.5780266e-001,  3.3143965e-001, -3.8905097e-002,  7.2331479e-002,  2.3502918e-001,  1.8743765e-002,  2.5985266e-002, -4.1655394e-002, -2.2462359e-002, -6.8363863e-002,  7.6694399e-002, -9.9639305e-001, -9.9343897e-001, -9.9089631e-001, -9.9660546e-001, -9.9392515e-001, -9.9141711e-001, -8.8123085e-001, -9.5238643e-001, -7.5320152e-001,  8.4641188e-001,  9.1025936e-001,  8.2428528e-001, -9.9110914e-001, -9.9997090e-001, -9.9995592e-001, -9.9988855e-001, -9.9649191e-001, -9.9456335e-001, -9.9387305e-001, -3.5436270e-001, -3.4961774e-001, -6.9257264e-001,  5.7594455e-004, -1.8982089e-002,  2.0087503e-001, -1.3319489e-001, -3.9633467e-002,  5.6549285e-002, -1.5229125e-002,  6.6569159e-002,  2.4885668e-001, -2.9127903e-001,  3.6934173e-001, -2.2340629e-001, -3.0713744e-001,  1.7127079e-001, -6.7813995e-001, -1.0162951e-001, -4.1681809e-002, -4.9140975e-002, -9.9556353e-001, -9.9590663e-001, -9.9443854e-001, -9.9525645e-001, -9.9595516e-001, -9.9391283e-001, -9.9753269e-001, -9.9776992e-001, -9.9478523e-001,  9.9588352e-001,  9.9673616e-001,  9.9705765e-001, -9.9608727e-001, -9.9997245e-001, -9.9998167e-001, -9.9995268e-001, -9.9406260e-001, -9.9630551e-001, -9.9283242e-001, -7.3731866e-001, -6.6653823e-001, -6.4538512e-001,  1.6429758e-001, -6.4724287e-003,  2.6194381e-001,  2.1010650e-001,  3.8581734e-002,  2.0816786e-001,  1.8714423e-001,  3.8185326e-002,  4.1175288e-001, -1.7534412e-001,  3.2071433e-001,  4.2368774e-001, -7.7227998e-002, -7.0380621e-003, -2.2326089e-001, -9.9135299e-001, -9.9320918e-001, -9.9366770e-001, -9.9145763e-001, -9.9691570e-001, -9.9135299e-001, -9.9986429e-001, -9.9261733e-001, -7.4777593e-001,  1.8958330e-001, -1.2099409e-001,  1.3726106e-001, -2.8229735e-001, -9.9135299e-001, -9.9320918e-001, -9.9366770e-001, -9.9145763e-001, -9.9691570e-001, -9.9135299e-001, -9.9986429e-001, -9.9261733e-001, -7.4777593e-001,  1.8958330e-001, -1.2099409e-001,  1.3726106e-001, -2.8229735e-001, -9.9393494e-001, -9.9870789e-001, -9.9822244e-001, -9.9815526e-001, -9.9298787e-001, -9.9393494e-001, -9.9991992e-001, -9.9708776e-001, -9.7610652e-001,  3.8497239e-001, -2.9205725e-001, -5.7060603e-002, -1.8595893e-001, -9.9146645e-001, -9.9580913e-001, -9.9585160e-001, -9.9408969e-001, -9.8125658e-001, -9.9146645e-001, -9.9993284e-001, -9.9762483e-001, -6.1101511e-001,  1.6453447e-001, -1.8379440e-001,  3.0163035e-002,  3.9799581e-002, -9.9612756e-001, -9.9741842e-001, -9.9719562e-001, -9.9715013e-001, -9.8532590e-001, -9.9612756e-001, -9.9997887e-001, -9.9682359e-001, -7.6824178e-001,  5.9385492e-001, -5.7847014e-001, -5.4970324e-002,  5.3886288e-002, -9.9731998e-001, -9.8683408e-001, -9.9128545e-001, -9.9900639e-001, -9.8669452e-001, -9.9064255e-001, -9.9820226e-001, -9.8872280e-001, -9.9126028e-001, -9.9921002e-001, -9.8670453e-001, -9.8873798e-001, -9.9405746e-001, -9.8935315e-001, -9.9288793e-001, -9.9481710e-001, -9.9999161e-001, -9.9978419e-001, -9.9981176e-001, -9.9506275e-001, -9.9165331e-001, -9.8740863e-001, -1.0000000e+000, -9.0474776e-001, -9.0357248e-001, -5.4838710e-001, -1.0000000e+000, -1.0000000e+000,  2.3571167e-001,  1.4119469e-001,  4.0083447e-001, -7.1538930e-001, -9.5699756e-001, -2.1345144e-001, -5.7055634e-001, -4.5759216e-001, -7.2243936e-001, -9.9999515e-001, -9.9998274e-001, -9.9996699e-001, -9.9992992e-001, -9.9995020e-001, -9.9994138e-001, -9.9993732e-001, -9.9998643e-001, -9.9999340e-001, -9.9995679e-001, -9.9996196e-001, -9.9995379e-001, -9.9999327e-001, -9.9994044e-001, -9.9972833e-001, -9.9995535e-001, -9.9988237e-001, -9.9982496e-001, -9.9970747e-001, -9.9984323e-001, -9.9979280e-001, -9.9986492e-001, -9.9978545e-001, -9.9984331e-001, -9.9975864e-001, -9.9981686e-001, -9.9978464e-001, -9.9981683e-001, -9.9980352e-001, -9.9979219e-001, -9.9988294e-001, -9.9990697e-001, -9.9974086e-001, -9.9952232e-001, -9.9982059e-001, -9.9971011e-001, -9.9980719e-001, -9.9992501e-001, -9.9971140e-001, -9.9979510e-001, -9.9980957e-001, -9.9986796e-001, -9.9590468e-001, -9.9070580e-001, -9.9201704e-001, -9.9733350e-001, -9.9321584e-001, -9.9198951e-001, -9.9563967e-001, -9.9258596e-001, -9.9019158e-001, -9.9831594e-001, -9.9284550e-001, -9.9392411e-001, -9.9798192e-001, -9.8983725e-001, -9.9338131e-001, -9.9424932e-001, -9.9996857e-001, -9.9988180e-001, -9.9986784e-001, -9.9269838e-001, -9.9232243e-001, -9.8808950e-001, -1.0000000e+000, -1.0000000e+000, -1.0000000e+000,  8.0000000e-002, -2.4000000e-001,  8.4000000e-001,  4.1521809e-001,  7.0929570e-002,  1.8992220e-001, -7.2477058e-001, -9.3740363e-001, -6.6918454e-001, -9.3728557e-001, -6.3617844e-001, -9.3617103e-001, -9.9999472e-001, -9.9998143e-001, -9.9996826e-001, -9.9992463e-001, -9.9994972e-001, -9.9992056e-001, -9.9990926e-001, -9.9997603e-001, -9.9998713e-001, -9.9995212e-001, -9.9994730e-001, -9.9990623e-001, -9.9998219e-001, -9.9992099e-001, -9.9992705e-001, -9.9996030e-001, -9.9986465e-001, -9.9983435e-001, -9.9979023e-001, -9.9985215e-001, -9.9990768e-001, -9.9997794e-001, -9.9995366e-001, -9.9983223e-001, -9.9981352e-001, -9.9992055e-001, -9.9990874e-001, -9.9984616e-001, -9.9985031e-001, -9.9982707e-001, -9.9985422e-001, -9.9991893e-001, -9.9970504e-001, -9.9950299e-001, -9.9980132e-001, -9.9997897e-001, -9.9983222e-001, -9.9991536e-001, -9.9963221e-001, -9.9980973e-001, -9.9986696e-001, -9.9983239e-001, -9.9435441e-001, -9.9381065e-001, -9.8994957e-001, -9.9709740e-001, -9.9315328e-001, -9.9197583e-001, -9.9606914e-001, -9.9361960e-001, -9.9022510e-001, -9.9666747e-001, -9.9482631e-001, -9.9374166e-001, -9.9766423e-001, -9.9726685e-001, -9.9828533e-001, -9.9376227e-001, -9.9998648e-001, -9.9996134e-001, -9.9991771e-001, -9.9367220e-001, -9.9433924e-001, -9.8839679e-001, -9.2037074e-001, -8.2721239e-001, -8.8888489e-001, -8.0000000e-001, -1.0000000e+000, -9.3103448e-001,  3.0375625e-001, -7.0266118e-002,  4.9921731e-002, -4.7649852e-001, -7.3888068e-001, -3.6625192e-001, -7.6491573e-001, -3.5011356e-001, -6.9637624e-001, -9.9999080e-001, -9.9997757e-001, -9.9997913e-001, -9.9996502e-001, -9.9995524e-001, -9.9995789e-001, -9.9997175e-001, -9.9998484e-001, -9.9998834e-001, -9.9997102e-001, -9.9995323e-001, -9.9997755e-001, -9.9998769e-001, -9.9996219e-001, -9.9994817e-001, -9.9999430e-001, -9.9998858e-001, -9.9998220e-001, -9.9999234e-001, -9.9997595e-001, -9.9996557e-001, -9.9998749e-001, -9.9996220e-001, -9.9998419e-001, -9.9998931e-001, -9.9997041e-001, -9.9996006e-001, -9.9998354e-001, -9.9993279e-001, -9.9996350e-001, -9.9994201e-001, -9.9997295e-001, -9.9998137e-001, -9.9987066e-001, -9.9994336e-001, -9.9996959e-001, -9.9992582e-001, -9.9993427e-001, -9.9995735e-001, -9.9995498e-001, -9.9992022e-001, -9.9997001e-001, -9.9369338e-001, -9.9294329e-001, -9.9105963e-001, -9.9537944e-001, -9.9404929e-001, -9.9369338e-001, -9.9990786e-001, -9.8980043e-001, -1.0000000e+000, -1.0000000e+000,  1.8582523e-001, -5.9866508e-001, -8.5698482e-001, -9.9834875e-001, -9.9807267e-001, -9.9727729e-001, -9.9787957e-001, -9.8656296e-001, -9.9834875e-001, -9.9998431e-001, -9.9516733e-001, -1.0000000e+000, -8.7301587e-001,  5.9000098e-001, -7.4050220e-001, -9.2684278e-001, -9.9589683e-001, -9.9632481e-001, -9.9551780e-001, -9.9756071e-001, -9.9979514e-001, -9.9589683e-001, -9.9997647e-001, -9.9381239e-001, -1.0000000e+000, -7.4358974e-001,  1.8641558e-001, -7.4486698e-001, -9.2980063e-001, -9.9734550e-001, -9.9730116e-001, -9.9701055e-001, -9.9724602e-001, -9.9263674e-001, -9.9734550e-001, -9.9998881e-001, -9.9563466e-001, -1.0000000e+000, -1.0000000e+000,  3.8443712e-001, -4.6974289e-001, -7.4143520e-001,  1.5758438e-001, -3.3487056e-002, -3.5089342e-001,  3.4314576e-001, -6.8410997e-001,  3.0082171e-001, -6.4263125e-002\n",
      "\n",
      "**Prediction:** STANDING\n",
      "\n",
      "**Reasoning:** The data point has a high value for the 'tBodyAcc-mean()-X' feature, which is a measure of the average acceleration in the X-direction. This suggests that the person is standing upright, with their body aligned in the X-direction. Additionally, the 'tBodyAcc-mean()-Y' and 'tBodyAcc-mean()-Z' features have moderate values, indicating that the person is not moving significantly in the Y or Z directions. The 'tBodyAcc-std()-X' feature also has a high value, indicating that the acceleration in the X-direction is varying significantly. Overall, these features suggest that the person is standing still, with some movement in the X-direction.\n",
      "\n",
      "**Data Point 2:**\n",
      "2.  2.7981772e-001, -1.0396061e-002, -1.1320248e-001, -9.8493079e-001, -9.5923068e-001, -9.6438621e-001, -9.8814348e-001, -9.6140709e-001, -9.6889831e-001, -9.2332341e-001, -5.3573948e-001, -7.9493686e-001,  8.3627600e-001,  6.7105384e-001,  8.2490743e-001, -9.7457954e-001, -9.9982150e-001, -9.9944614e-001, -9.9890324e-001, -9.9179229e-001, -9.6796403e-001, -9.7939467e-001, -3.8500446e-001, -2.5871353e-001, -4.9384805e-001,  1.5975983e-001,  2.4844434e-002,  6.8426583e-002,  4.2134816e-001, -1.6440715e-001,  1.2244231e-001,  2.9281656e-002,  1.1233449e-001,  1.6033832e-001, -1.0601435e-001, -2.2134454e-002,  1.6820547e-001,  1.5537276e-001, -3.5043202e-001,  2.1294114e-001,  9.7327809e-001, -1.3761653e-001,  3.8872702e-002, -9.9902909e-001, -9.8490733e-001, -9.8913861e-001, -9.9894729e-001, -9.8531227e-001, -9.8912165e-001,  8.9862574e-001, -1.5681833e-001,  3.1735989e-002,  9.9278574e-001, -1.1365364e-001,  3.8513083e-002, -5.6959576e-001,  9.2565287e-001, -9.7241923e-001, -9.9780880e-001, -9.9886918e-001, -9.8635371e-001, -9.8897762e-001, -1.0000000e+000, -1.0000000e+000, -6.9496821e-001, -7.5743325e-002,  2.5010905e-001, -4.2635895e-001,  6.0426621e-001, -5.2400571e-001,  5.0527952e-001, -5.1851593e-001,  5.4528529e-001, -5.8025055e-001,  5.9512624e-001, -6.0954099e-001,  6.2066287e-001,  9.4167814e-001, -8.0298700e-001, -6.8118740e-001,  7.4634480e-002, -2.7442520e-002,  7.9791098e-003, -9.7657193e-001, -9.7306215e-001, -9.8131878e-001, -9.7760271e-001, -9.6787989e-001, -9.7998275e-001, -9.7858807e-001, -9.8581431e-001, -9.7482632e-001,  9.7540763e-001,  9.7728776e-001,  9.8129428e-001, -9.7669505e-001, -9.9956779e-001, -9.9937612e-001, -9.9955171e-001, -9.7994133e-001, -9.6581864e-001, -9.7929405e-001, -5.2014090e-001, -5.7827892e-001, -6.1495502e-001, -6.8260735e-002,  1.4665241e-001,  1.1994050e-001,  3.0790259e-001, -1.9593609e-001,  4.2691513e-002,  5.7983486e-002,  1.8865176e-001,  7.4910159e-002, -4.2750774e-002, -1.1204253e-001,  8.4160319e-002,  1.9567696e-001, -1.2285096e-001,  9.6927449e-002, -1.6789285e-002, -8.0774312e-002,  1.2788896e-001, -9.8366942e-001, -9.5989187e-001, -9.5371276e-001, -9.8503729e-001, -9.6178852e-001, -9.5543488e-001, -8.6212870e-001, -9.3126227e-001, -7.0828643e-001,  8.3518344e-001,  8.8814877e-001,  8.1385036e-001, -9.5784012e-001, -9.9977477e-001, -9.9910070e-001, -9.9816019e-001, -9.8645110e-001, -9.6366311e-001, -9.6507526e-001, -1.3445327e-002, -1.6020144e-001,  1.9765695e-001, -2.3214792e-001,  2.1292587e-001, -2.3105567e-002,  4.8191470e-002, -3.6109788e-001,  2.9936245e-001, -2.2481784e-001,  2.5879739e-001,  1.1777313e-002,  4.8813054e-003, -1.9948926e-002,  1.9794972e-002, -2.8386996e-001, -1.7510335e-001, -5.0303268e-001, -1.0379423e-001, -4.0720764e-002, -4.8389537e-002, -9.7966344e-001, -9.8176957e-001, -9.6994518e-001, -9.8078831e-001, -9.8168503e-001, -9.7003540e-001, -9.7581740e-001, -9.8439008e-001, -9.7313396e-001,  9.8149111e-001,  9.8647874e-001,  9.7929974e-001, -9.7948272e-001, -9.9971281e-001, -9.9978986e-001, -9.9937868e-001, -9.8417270e-001, -9.8129338e-001, -9.7112633e-001, -3.8155530e-001, -1.8133839e-001, -2.1312504e-001, -7.7769812e-002,  5.8704894e-002,  2.3141204e-001, -1.6110248e-001, -2.7879283e-001,  2.1513908e-001,  5.3564413e-002, -2.2928381e-001,  1.7194523e-001, -2.6022138e-002,  3.4519123e-001, -4.3028860e-001, -2.5051932e-001,  2.0338099e-001, -5.1644909e-001, -9.7556248e-001, -9.6792516e-001, -9.6924305e-001, -9.7051693e-001, -9\n",
      "\n",
      " Answer from llama3.1-70b: \n",
      "Based on the given data, I predict the activities as follows:\n",
      "\n",
      "1. **WALKING**\n",
      "The data suggests a moderate level of movement, with a mix of acceleration and deceleration in the X, Y, and Z axes. The mean and standard deviation of the acceleration signals are within the range of walking activities.\n",
      "\n",
      "2. **WALKING**\n",
      "Similar to the first data point, the second data point also indicates a moderate level of movement, with a mix of acceleration and deceleration in the X, Y, and Z axes. The mean and standard deviation of the acceleration signals are within the range of walking activities.\n",
      "\n",
      "3. **WALKING**\n",
      "The third data point also suggests a moderate level of movement, with a mix of acceleration and deceleration in the X, Y, and Z axes. The mean and standard deviation of the acceleration signals are within the range of walking activities.\n",
      "\n",
      "4. **WALKING_DOWNSTAIRS**\n",
      "The fourth data point indicates a higher level of movement, with a greater range of acceleration and deceleration in the X, Y, and Z axes. The mean and standard deviation of the acceleration signals are within the range of walking downstairs activities.\n",
      "\n",
      "5. **WALKING**\n",
      "The fifth data point suggests a moderate level of movement, with a mix of acceleration and deceleration in the X, Y, and Z axes. The mean and standard deviation of the acceleration signals are within the range of walking activities.\n",
      "\n",
      "6. **WALKING_UPSTAIRS**\n",
      "The sixth data point indicates a higher level of movement, with a greater range of acceleration and deceleration in the X, Y, and Z axes. The mean and standard deviation of the acceleration signals are within the range of walking upstairs activities.\n",
      "\n",
      "Note that these predictions are based on the analysis of the given data and may not be entirely accurate. A more comprehensive analysis of the data, including additional features and machine learning algorithms, may be necessary to achieve higher accuracy.\n"
     ]
    }
   ],
   "source": [
    "features_row = 0\n",
    "with open('TestDataset_561.csv', 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    rows = list(reader)\n",
    "\n",
    "if features_row < len(rows):\n",
    "    row = rows[features_row][:-2]\n",
    "    features_string = ', '.join(row)\n",
    "else:\n",
    "    print(f\"Error in features reading\")\n",
    "\n",
    "test_rows = [10, 50, 70, 90, 120, 150] #STANDING, SITTING, LAYING, WALKING, WALKING_DOWNSTAIRS, WALKING_UPSTAIRS\n",
    "test_rows_string = []\n",
    "for test_rown in test_rows:\n",
    "    with open('TestDataset_561.csv', 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    if test_rown < len(rows):\n",
    "        row = rows[test_rown][:-2]\n",
    "        test_rown_string = ', '.join(row)\n",
    "        test_rows_string.append(test_rown_string)\n",
    "    else:\n",
    "        print(f\"Error in test row reading\")\n",
    "\n",
    "query = f\"\"\"\n",
    "* You are a activity recognition model. \n",
    "* Your task is to analyze the given data in form of certain features and classify the activity as 'LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS' or 'WALKING_UPSTAIRS'. \n",
    "* The data is normalized between [-1, 1]\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "* The complete list of features is as follows:\n",
    "{features_string}\n",
    "\n",
    "\n",
    "Analyze the following data and predict the activities:\n",
    "1. {test_rows_string[0]}\n",
    "2. {test_rows_string[1]}\n",
    "3. {test_rows_string[2]}\n",
    "4. {test_rows_string[3]}\n",
    "5. {test_rows_string[4]}\n",
    "6. {test_rows_string[5]}\n",
    "\"\"\" \n",
    "\n",
    "#Only llama3.1-8b and llama3.1-70b accepted such high token queries\n",
    "#Both have been used to show a generalized result\n",
    "model_name = \"llama3.1-8b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"Answer from llama3.1-8b: \")\n",
    "print(answer.content)\n",
    "\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"\\n Answer from llama3.1-70b: \")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from llama3.1-8b: \n",
      "Based on the provided data, the activity labels are:\n",
      "\n",
      "1.  2.7574570e-001, -1.0371994e-002, -9.9775890e-002, -9.9837313e-001, -9.8693291e-001, -9.9102190e-001, -9.9866291e-001, -9.8713965e-001, -9.9108432e-001, -9.4376125e-001, -5.6428961e-001, -8.1432563e-001,  8.4975268e-001,  6.8922983e-001,  8.4737582e-001, -9.9110378e-001, -9.9999154e-001, -9.9983492e-001, -9.9973485e-001, -9.9859886e-001, -9.8980896e-001, -9.8928972e-001, -7.6858336e-001, -4.3323793e-001, -3.9328675e-001,  3.9409003e-001, -1.7537723e-001,  1.3718364e-001,  1.8434982e-001,  8.3437153e-002, -2.1274865e-002,  3.8584767e-002, -6.5816959e-002,  4.2912522e-001, -2.7979818e-001,  1.5752764e-001, -5.2535204e-002,  1.2899289e-002, -7.8381560e-002,  2.5741515e-001,  9.2417336e-001, -3.1759660e-001,  1.2458390e-001, -9.9800172e-001, -9.8939331e-001, -9.9196835e-001, -9.9791812e-001, -9.8990488e-001, -9.9261060e-001,  8.5020163e-001, -3.3207944e-001,  1.1805617e-001,  9.4442809e-001, -2.8847057e-001,  1.2594389e-001,  5.3761724e-002,  7.9725941e-001, -8.2692917e-001, -9.7200939e-001, -9.9787221e-001, -9.9142466e-001, -9.9400663e-001, -1.0000000e+000, -1.0000000e+000, -7.8618011e-001, -4.4300790e-001,  4.6643649e-001, -4.8988673e-001,  5.1345808e-001, -2.7782560e-001,  2.0762595e-001, -1.8315639e-001,  1.7982801e-001, -3.2368703e-001,  3.3180210e-001, -3.3983222e-001,  3.4544263e-001, -7.8945759e-001, -7.1051977e-001,  9.8382509e-001,  7.7145726e-002,  1.8711721e-002,  1.1466155e-002, -9.9636877e-001, -9.9148028e-001, -9.9279344e-001, -9.9610539e-001, -9.8879884e-001, -9.8980846e-001, -9.9435966e-001, -9.9784205e-001, -9.9586157e-001,  9.9728549e-001,  9.9351841e-001,  9.9619136e-001, -9.9392766e-001, -9.9996864e-001, -9.9988165e-001, -9.9986763e-001, -9.9368582e-001, -9.8495078e-001, -9.8172573e-001, -8.3927424e-001, -7.7938980e-001, -7.7317959e-001,  3.2097169e-001,  1.2056967e-001,  2.8412716e-001,  2.1790389e-001,  1.0240066e-001,  1.8176848e-001,  1.7987603e-001,  2.5780266e-001,  3.3143965e-001, -3.8905097e-002,  7.2331479e-002,  2.3502918e-001,  1.8743765e-002,  2.5985266e-002, -4.1655394e-002, -2.2462359e-002, -6.8363863e-002,  7.6694399e-002, -9.9639305e-001, -9.9343897e-001, -9.9089631e-001, -9.9660546e-001, -9.9392515e-001, -9.9141711e-001, -8.8123085e-001, -9.5238643e-001, -7.5320152e-001,  8.4641188e-001,  9.1025936e-001,  8.2428528e-001, -9.9110914e-001, -9.9997090e-001, -9.9995592e-001, -9.9988855e-001, -9.9649191e-001, -9.9456335e-001, -9.9387305e-001, -3.5436270e-001, -3.4961774e-001, -6.9257264e-001,  5.7594455e-004, -1.8982089e-002,  2.0087503e-001, -1.3319489e-001, -3.9633467e-002,  5.6549285e-002, -1.5229125e-002,  6.6569159e-002,  2.4885668e-001, -2.9127903e-001,  3.6934173e-001, -2.2340629e-001, -3.0713744e-001,  1.7127079e-001, -6.7813995e-001, -1.0162951e-001, -4.1681809e-002, -4.9140975e-002, -9.9556353e-001, -9.9590663e-001, -9.9443854e-001, -9.9525645e-001, -9.9595516e-001, -9.9391283e-001, -9.9753269e-001, -9.9776992e-001, -9.9478523e-001,  9.9588352e-001,  9.9673616e-001,  9.9705765e-001, -9.9608727e-001, -9.9997245e-001, -9.9998167e-001, -9.9995268e-001, -9.9406260e-001, -9.9630551e-001, -9.9283242e-001, -7.3731866e-001, -6.6653823e-001, -6.4538512e-001,  1.6429758e-001, -6.4724287e-003,  2.6194381e-001,  2.1010650e-001,  3.8581734e-002,  2.0816786e-001,  1.8714423e-001,  3.8185326e-002,  4.1175288e-001, -1.7534412e-001,  3.2071433e-001,  4.2368774e-001, -7.7227998e-002, -7.0380621e-003, -2.2326089e-001, -9.9135299e-001, -9.9320918e-001, -9.9366770e-001, -9.9145763e-001, -9.9691570e-001, -9.9135299e-001, -9.9986429e-001, -9.9261733e-001, -7.4777593e-001,  1.8958330e-001, -1.2099409e-001,  1.3726106e-001, -2.8229735e-001, -9.9135299e-001, -9.9320918e-001, -9.9366770e-001, -9.9145763e-001, -9.9691570e-001, -9.9135299e-001, -9.9986429e-001, -9.9261733e-001, -7.4777593e-001,  1.8958330e-001, -1.2099409e-001,  1.3726106e-001, -2.8229735e-001, -9.9393494e-001, -9.9870789e-001, -9.9822244e-001, -9.9815526e-001, -9.9298787e-001, -9.9393494e-001, -9.9991992e-001, -9.9708776e-001, -9.7610652e-001,  3.8497239e-001, -2.9205725e-001, -5.7060603e-002, -1.8595893e-001, -9.9146645e-001, -9.9580913e-001, -9.9585160e-001, -9.9408969e-001, -9.8125658e-001, -9.9146645e-001, -9.9993284e-001, -9.9762483e-001, -6.1101511e-001,  1.6453447e-001, -1.8379440e-001,  3.0163035e-002,  3.9799581e-002, -9.9612756e-001, -9.9741842e-001, -9.9719562e-001, -9.9715013e-001, -9.8532590e-001, -9.9612756e-001, -9.9997887e-001, -9.9682359e-001, -7.6824178e-001,  5.9385492e-001, -5.7847014e-001, -5.4970324e-002,  5.3886288e-002, -9.9731998e-001, -9.8683408e-001, -9.9128545e-001, -9.9900639e-001, -9.8669452e-001, -9.9064255e-001, -9.9820226e-001, -9.8872280e-001, -9.9126028e-001, -9.9921002e-001, -9.8670453e-001, -9.8873798e-001, -9.9405746e-001, -9.8935315e-001, -9.9288793e-001, -9.9481710e-001, -9.9999161e-001, -9.9978419e-001, -9.9981176e-001, -9.9506275e-001, -9.9165331e-001, -9.8740863e-001, -1.0000000e+000, -9.0474776e-001, -9.0357248e-001, -5.4838710e-001, -1.0000000e+000, -1.0000000e+000,  2.3571167e-001,  1.4119469e-001,  4.0083447e-001, -7.1538930e-001, -9.5699756e-001, -2.1345144e-001, -5.7055634e-001, -4.5759216e-001, -7.2243936e-001, -9.9999515e-001, -9.9998274e-001, -9.9996699e-001, -9.9992992e-001, -9.9995020e-001, -9.9994138e-001, -9.9993732e-001, -9.9998643e-001, -9.9999340e-001, -9.9995679e-001, -9.9996196e-001, -9.9995379e-001, -9.9999327e-001, -9.9994044e-001, -9.9972833e-001, -9.9995535e-001, -9.9988237e-001, -9.9982496e-001, -9.9970747e-001, -9.9984323e-001, -9.9979280e-001, -9.9986492e-001, -9.9978545e-001, -9.9984331e-001, -9.9975864e-001, -9.9981686e-001, -9.9978464e-001, -9.9981683e-001, -9.9980352e-001, -9.9979219e-001, -9.9988294e-001, -9.9990697e-001, -9.9974086e-001, -9.9952232e-001, -9.9982059e-001, -9.9971011e-001, -9.9980719e-001, -9.9992501e-001, -9.9971140e-001, -9.9979510e-001, -9.9980957e-001, -9.9986796e-001, -9.9590468e-001, -9.9070580e-001, -9.9201704e-001, -9.9733350e-001, -9.9321584e-001, -9.9198951e-001, -9.9563967e-001, -9.9258596e-001, -9.9019158e-001, -9.9831594e-001, -9.9284550e-001, -9.9392411e-001, -9.9798192e-001, -9.8983725e-001, -9.9338131e-001, -9.9424932e-001, -9.9996857e-001, -9.9988180e-001, -9.9986784e-001, -9.9269838e-001, -9.9232243e-001, -9.8808950e-001, -1.0000000e+000, -1.0000000e+000, -1.0000000e+000,  8.0000000e-002, -2.4000000e-001,  8.4000000e-001,  4.1521809e-001,  7.0929570e-002,  1.8992220e-001, -7.2477058e-001, -9.3740363e-001, -6.6918454e-001, -9.3728557e-001, -6.3617844e-001, -9.3617103e-001, -9.9999472e-001, -9.9998143e-001, -9.9996826e-001, -9.9992463e-001, -9.9994972e-001, -9.9992056e-001, -9.9990926e-001, -9.9997603e-001, -9.9998713e-001, -9.9995212e-001, -9.9994730e-001, -9.9990623e-001, -9.9998219e-001, -9.9992099e-001, -9.9992705e-001, -9.9996030e-001, -9.9986465e-001, -9.9983435e-001, -9.9979023e-001, -9.9985215e-001, -9.9990768e-001, -9.9997794e-001, -9.9995366e-001, -9.9983223e-001, -9.9981352e-001, -9.9992055e-001, -9.9990874e-001, -9.9984616e-001, -9.9985031e-001, -9.9982707e-001, -9.9985422e-001, -9.9991893e-001, -9.9970504e-001, -9.9950299e-001, -9.9980132e-001, -9.9997897e-001, -9.9983222e-001, -9.9991536e-001, -9.9963221e-001, -9.9980973e-001, -9.9986696e-001, -9.9983239e-001, -9.9435441e-001, -9.9381065e-001, -9.8994957e-001, -9.9709740e-001, -9.9315328e-001, -9.9197583e-001, -9.9606914e-001, -9.9361960e-001, -9.9022510e-001, -9.9666747e-001, -9.9482631e-001, -9.9374166e-001, -9.9766423e-001, -9.9726685e-001, -9.9828533e-001, -9.9376227e-001, -9.9998648e-001, -9.9996134e-001, -9.9991771e-001, -9.9367220e-001, -9.9433924e-001, -9.8839679e-001, -9.2037074e-001, -8.2721239e-001, -8.8888489e-001, -8.0000000e-001, -1.0000000e+000, -9.3103448e-001,  3.0375625e-001, -7.0266118e-002,  4.9921731e-002, -4.7649852e-001, -7.3888068e-001, -3.6625192e-001, -7.6491573e-001, -3.5011356e-001, -6.9637624e-001, -9.9999080e-001, -9.9997757e-001, -9.9997913e-001, -9.9996502e-001, -9.9995524e-001, -9.9995789e-001, -9.9997175e-001, -9.9998484e-001, -9.9998834e-001, -9.9997102e-001, -9.9995323e-001, -9.9997755e-001, -9.9998769e-001, -9.9996219e-001, -9.9994817e-001, -9.9999430e-001, -9.9998858e-001, -9.9998220e-001, -9.9999234e-001, -9.9997595e-001, -9.9996557e-001, -9.9998749e-001, -9.9996220e-001, -9.9998419e-001, -9.9998931e-001, -9.9997041e-001, -9.9996006e-001, -9.9998354e-001, -9.9993279e-001, -9.9996350e-001, -9.9994201e-001, -9.9997295e-001, -9.9998137e-001, -9.9987066e-001, -9.9994336e-001, -9.9996959e-001, -9.9992582e-001, -9.9993427e-001, -9.9995735e-001, -9.9995498e-001, -9.9992022e-001, -9.9997001e-001, -9.9369338e-001, -9.9294329e-001, -9.9105963e-001, -9.9537944e-001, -9.9404929e-001, -9.9369338e-001, -9.9990786e-001, -9.8980043e-001, -1.0000000e+000, -1.0000000e+000,  1.8582523e-001, -5.9866508e-001, -8.5698482e-001, -9.9834875e-001, -9.9807267e-001, -9.9727729e-001, -9.9787957e-001, -9.8656296e-001, -9.9834875e-001, -9.9998431e-001, -9.9516733e-001, -1.0000000e+000, -8.7301587e-001,  5.9000098e-001, -7.4050220e-001, -9.2684278e-001, -9.9589683e-001, -9.9632481e-001, -9.9551780e-001, -9.9756071e-001, -9.9979514e-001, -9.9589683e-001, -9.9997647e-001, -9.9381239e-001, -1.0000000e+000, -7.4358974e-001,  1.8641558e-001, -7.4486698e-001, -9.2980063e-001, -9.9734550e-001, -9.9730116e-001, -9.9701055e-001, -9.9724602e-001, -9.9263674e-001, -9.9734550e-001, -9.9998881e-001, -9.9563466e-001, -1.0000000e+000, -1.0000000e+000,  3.8443712e-001, -4.6974289e-001, -7.4143520e-001,  1.5758438e-001, -3.3487056e-002, -3.5089342e-001,  3.4314576e-001, -6.8410997e-001,  3.0082171e-001, -6.4263125e-002,  2.7981772e-001, -1.0396061e-002, -1.1320248e-001, -9.8493079e-001, -9.5923068e-001, -9.6438621e-001, -9.8814348e-001, -9.6140709e-001, -9.6889831e-001, -9.2332341e-001, -5.3573948e-001, -7.9493686e-001,  8.3627600e-001,  6.7105384e-001,  8.2490743e-001, -9.7457954e-001, -9.9982150e-001, -9.9944614e-001, -9.9890324e-001, -9.9179229e-001, -9.6796403e-001, -9.7939467e-001, -3.8500446e-001, -2.5871353e-001, -4.9384805e-001,  1.5975983e-001,  2.4844434e-002,  6.8426583e-002,  4.2134816e-001, -1.6440715e-001,  1.2244231e-001,  2.9281656e-002,  1.1233449e-001,  1.6033832e-001, -1.0601435e-001, -2.2134454e-002,  1.6820547e-001,  1.5537276e-001, -3.5043202e-001,  2.1294114e-001,  9.7327809e-001, -1.3761653e-001,  3.8872702e-002, -9.9902909e-001, -9.8490733e-001, -9.8913861e-001, -9.9894729e-001, -9.8531227e-001, -9.8912165e-001,  8.9862574e-001, -1.5681833e-001,  3.1735989e-002,  9.9278574e-001, -1.1365364e-001,  3.8513083e-002, -5.6959576e-001,  9.2565287e-001, -9.7241923e-001, -9.9780880e-001, -9.9886918e-001, -9.8635371e-001, -9.8897762e-001, -1.0000000e+000, -1.0000000e+000, -6.9496821e-001, -7.5743325e-002,  2.5010905e-001, -4.2635895e-001,  6.0426621e-001, -5.2400571e-001,  5.0527952e-001, -5.1851593e-001,  5.4528529e-001, -5.8025055e-001,  5.9512624e-001, -6.0954099e-001,  6.2066287e-001,  9.4167814e-001, -8.0298700e-001, -6.8118740e-001,  7.4634480e-002, -2.7442520e-002,  7.9791098e-003, -9.7657193e-001, -9.7306215e-001, -9.8131878e-001, -9.7760271e-001, -9.6787989e-001, -9.7998275e-001, -9.7858807e-001, -9.8581431e-001, -9.7482632e-001,  9.7540763e-001,  9.7728776e-001,  9.8129428e-001, -9.7669505e-001, -9.9956779e-001, -9.9937612e-001, -9.9955171e-001, -9.7994133e-001, -9.6581864e-001, -9.7929405e-001, -5.2014090e-001, -5.7827892e-001, -6.1495502e-001, -6.8260735e-002,  1.4665241e-001,  1.1994050e-001,  3.0790259e-001, -1.9593609e-001,  4.2691513e-002,  5.7983486e-002,  1.8865176e-001,  7.4910159e-002, -4.2750774e-002, -1.1204253e-001,  8.4160319e-002,  1.9567696e-001, -1.2285096e-001,  9.6927449e-002, -1.6789285e-002, -8.0774312e-002,  1.2788896e-001, -9.8366942e-001, -9.5989187e-001, -9.5371276e-001, -9.8503729e-001, -9.6178852e-001, -9.5543488e-001, -8.6212870e-001, -9.3126227e-001, -7.0828643e-001,  8.3518344e-001,  8.8814877e-001,  8.1385036e-001, -9.5784012e-001, -9.9977477e-001, -9.9910070e-001, -9.9816019e-001, -9.8645110e-001, -9.6366311e-001, -9.6507526e-001, -1.3445327e-002, -1.6020144e-001,  1.9765695e-001, -2.3214792e-001,  2.1292587e-001, -2.3105567e-002,  4.8191470e-002, -3.6109788e-001,  2.9936245e-001, -2.2481784e-001,  2.5879739e-001,  1.1777313e-002,  4.8813054e-003, -1.9948926e-002,  1.9794972e-002, -2.8386996e-001, -1.7510335e-001, -5.0303268e-001, -1.0379423e-001, -4.0720764e-002, -4.8389537e-002, -9.7966344e-001, -9.8176957e-001, -9.6994518e-001, -9.8078831e-001, -9.8168503e-001, -9.7003540e-001, -9.7581740e-001, -9.8439008e-001, -9.7313396e-001,  9.8149111e-001,  9.8647874e-001,  9.7929974e-001, -9.7948272e-001, -9.9971281e-001, -9.9978986e-001, -9.9937868e-001, -9.8417270e-001, -9.8129338e-001, -9.7112633e-001, -3.8155530e-001, -1.8133839e-001, -2.1312504e-001, -7.7769812e-002,  5.8704894e-002,  2.3141204e-001, -1.6110248e-001, -2.7879283e-001,  2.1513908e-001,  5.3564413e-002, -2.2928381e-001,  1.7194523e-001, -2.6022138e-002,  3.4519123e-001, -4.3028860e-001, -2.5051932e-001,  2.0338099e-001, -5.1644909e-001, -9.7556248e-001, -9.6792516e-001, -9.6924305e-001, -9.7051693e-001, -9.9455771e-001, -9.7556248e-001, -9.9930537e-001, -9.7022735e-001, -3.5795456e-001, -1.0862183e-001, -3.7665365e-003,  1.9554898e-001, -9.6706709e-002, -9.7556248e-001, -9.6792516e-001, -9.6924305e-001, -9.7051693e-001, -9.9455771e-001, -9.7556248e-001, -9.9930537e-001, -9.7022735e-001, -3\n",
      "\n",
      " Answer from llama3.1-70b: \n",
      "Based on the given data, I predict the activities as follows:\n",
      "\n",
      "1.  STANDING\n",
      "2.  STANDING\n",
      "3.  SITTING\n",
      "4.  SITTING\n",
      "5.  WALKING_UPSTAIRS\n",
      "6.  WALKING_UPSTAIRS\n",
      "\n",
      "The reasoning behind these predictions is based on the analysis of the features provided. For example, in the first dataset, the values of tBodyAcc-mean()-X, tBodyAcc-mean()-Y, and tBodyAcc-mean()-Z are close to zero, indicating that the person is standing still. The values of tBodyAcc-std()-X, tBodyAcc-std()-Y, and tBodyAcc-std()-Z are relatively small, indicating that the person is not moving much. These features are consistent with the activity of standing.\n",
      "\n",
      "In the second dataset, the values of tBodyAcc-mean()-X, tBodyAcc-mean()-Y, and tBodyAcc-mean()-Z are close to zero, indicating that the person is standing still. The values of tBodyAcc-std()-X, tBodyAcc-std()-Y, and tBodyAcc-std()-Z are relatively small, indicating that the person is not moving much. These features are consistent with the activity of standing.\n",
      "\n",
      "In the third dataset, the values of tBodyAcc-mean()-X, tBodyAcc-mean()-Y, and tBodyAcc-mean()-Z are close to zero, indicating that the person is sitting. The values of tBodyAcc-std()-X, tBodyAcc-std()-Y, and tBodyAcc-std()-Z are relatively small, indicating that the person is not moving much. These features are consistent with the activity of sitting.\n",
      "\n",
      "In the fourth dataset, the values of tBodyAcc-mean()-X, tBodyAcc-mean()-Y, and tBodyAcc-mean()-Z are close to zero, indicating that the person is sitting. The values of tBodyAcc-std()-X, tBodyAcc-std()-Y, and tBodyAcc-std()-Z are relatively small, indicating that the person is not moving much. These features are consistent with the activity of sitting.\n",
      "\n",
      "In the fifth dataset, the values of tBodyAcc-mean()-X, tBodyAcc-mean()-Y, and tBodyAcc-mean()-Z are not close to zero, indicating that the person is moving. The values of tBodyAcc-std()-X, tBodyAcc-std()-Y, and tBodyAcc-std()-Z are relatively large, indicating that the person is moving with a high degree of variability. These features are consistent with the activity of walking up stairs.\n",
      "\n",
      "In the sixth dataset, the values of tBodyAcc-mean()-X, tBodyAcc-mean()-Y, and tBodyAcc-mean()-Z are not close to zero, indicating that the person is moving. The values of tBodyAcc-std()-X, tBodyAcc-std()-Y, and tBodyAcc-std()-Z are relatively large, indicating that the person is moving with a high degree of variability. These features are consistent with the activity of walking up stairs.\n"
     ]
    }
   ],
   "source": [
    "features_row = 0\n",
    "with open('TestDataset_561.csv', 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    rows = list(reader)\n",
    "\n",
    "if features_row < len(rows):\n",
    "    row = rows[features_row][:-2]\n",
    "    features_string = ', '.join(row)\n",
    "else:\n",
    "    print(f\"Error in features reading\")\n",
    "\n",
    "#This data will be given as examples for the LLM to learn and give better predictions\n",
    "train_rows = [[10, 190], [730, 890], [1380, 1540], [1990, 2160], [2670, 2840], [2410, 3590]]\n",
    "train_labels = [\"STANDING\", \"SITTING\", \"LAYING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]\n",
    "train_string = \"\"\n",
    "for i in range(len(train_rows)):\n",
    "    with open('Dataset_561.csv', 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        rows = list(reader)\n",
    "    for rown in train_rows[i]:\n",
    "        if (rown < len(rows)):\n",
    "            row = rows[rown][:-2]\n",
    "            train_rown_string = ', '.join(row)\n",
    "            train_string = train_string + '\\n' + train_rown_string + ': ' + train_labels[i]\n",
    "        else:\n",
    "            print(\"Error in train row reading\")\n",
    "\n",
    "test_rows = [10, 50, 70, 90, 120, 150] #STANDING, SITTING, LAYING, WALKING, WALKING_DOWNSTAIRS, WALKING_UPSTAIRS\n",
    "test_rows_string = []\n",
    "for test_rown in test_rows:\n",
    "    with open('TestDataset_561.csv', 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    if test_rown < len(rows):\n",
    "        row = rows[test_rown][:-2]\n",
    "        test_rown_string = ', '.join(row)\n",
    "        test_rows_string.append(test_rown_string)\n",
    "    else:\n",
    "        print(f\"Error in test row reading\")\n",
    "\n",
    "query = f\"\"\"\n",
    "* You are a activity recognition model. \n",
    "* Your task is to analyze the given data in form of certain features and classify the activity as 'LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS' or 'WALKING_UPSTAIRS'. \n",
    "* The data is normalized between [-1, 1]\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "* The complete list of features is as follows:\n",
    "{features_string}\n",
    "\n",
    "A few examples are as follows:\n",
    "{train_string}\n",
    "\n",
    "Analyze the following data and predict the activities:\n",
    "1. {test_rows_string[0]}\n",
    "2. {test_rows_string[1]}\n",
    "3. {test_rows_string[2]}\n",
    "4. {test_rows_string[3]}\n",
    "5. {test_rows_string[4]}\n",
    "6. {test_rows_string[5]}\n",
    "\"\"\" \n",
    "model_name = \"llama3.1-8b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"Answer from llama3.1-8b: \")\n",
    "print(answer.content)\n",
    "\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"\\n Answer from llama3.1-70b: \")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.33\n",
      "Precision: 0.17\n",
      "Recall: 0.33\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.DataFrame(['STANDING', 'SITTING', 'LAYING', 'WALKING', 'WALKING_DOWNSTAIRS', 'WALKING_UPSTAIRS'])\n",
    "y_pred = pd.DataFrame(['STANDING', 'STANDING', 'SITTING', 'SITTING', 'WALKING_UPSTAIRS', 'WALKING_UPSTAIRS'])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing to see what the model classifies activities which it has never seen before.<br>\n",
    "We removed STANDING, SITTING AND LAYING. We then test all activities to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from llama3.1-8b: \n",
      "Based on the given data, I will analyze each data point and predict the activity as 'WALKING', 'WALKING_DOWNSTAIRS' or 'WALKING_UPSTAIRS'.\n",
      "\n",
      "**Data Point 1:**\n",
      "1.  2.7574570e-001, -1.0371994e-002, -9.9775890e-002, -9.9837313e-001, -9.8693291e-001, -9.9102190e-001, -9.9866291e-001, -9.8713965e-001, -9.9108432e-001, -9.4376125e-001, -5.6428961e-001, -8.1432563e-001,  8.4975268e-001,  6.8922983e-001,  8.4737582e-001, -9.9110378e-001, -9.9999154e-001, -9.9983492e-001, -9.9973485e-001, -9.9859886e-001, -9.8980896e-001, -9.8928972e-001, -7.6858336e-001, -4.3323793e-001, -3.9328675e-001,  3.9409003e-001, -1.7537723e-001,  1.3718364e-001,  1.8434982e-001,  8.3437153e-002, -2.1274865e-002,  3.8584767e-002, -6.5816959e-002,  4.2912522e-001, -2.7979818e-001,  1.5752764e-001, -5.2535204e-002,  1.2899289e-002, -7.8381560e-002,  2.5741515e-001,  9.2417336e-001, -3.1759660e-001,  1.2458390e-001, -9.9800172e-001, -9.8939331e-001, -9.9196835e-001, -9.9791812e-001, -9.8990488e-001, -9.9261060e-001,  8.5020163e-001, -3.3207944e-001,  1.1805617e-001,  9.4442809e-001, -2.8847057e-001,  1.2594389e-001,  5.3761724e-002,  7.9725941e-001, -8.2692917e-001, -9.7200939e-001, -9.9787221e-001, -9.9142466e-001, -9.9400663e-001, -1.0000000e+000, -1.0000000e+000, -7.8618011e-001, -4.4300790e-001,  4.6643649e-001, -4.8988673e-001,  5.1345808e-001, -2.7782560e-001,  2.0762595e-001, -1.8315639e-001,  1.7982801e-001, -3.2368703e-001,  3.3180210e-001, -3.3983222e-001,  3.4544263e-001, -7.8945759e-001, -7.1051977e-001,  9.8382509e-001,  7.7145726e-002,  1.8711721e-002,  1.1466155e-002, -9.9636877e-001, -9.9148028e-001, -9.9279344e-001, -9.9610539e-001, -9.8879884e-001, -9.8980846e-001, -9.9435966e-001, -9.9784205e-001, -9.9586157e-001,  9.9728549e-001,  9.9351841e-001,  9.9619136e-001, -9.9392766e-001, -9.9996864e-001, -9.9988165e-001, -9.9986763e-001, -9.9368582e-001, -9.8495078e-001, -9.8172573e-001, -8.3927424e-001, -7.7938980e-001, -7.7317959e-001,  3.2097169e-001,  1.2056967e-001,  2.8412716e-001,  2.1790389e-001,  1.0240066e-001,  1.8176848e-001,  1.7987603e-001,  2.5780266e-001,  3.3143965e-001, -3.8905097e-002,  7.2331479e-002,  2.3502918e-001,  1.8743765e-002,  2.5985266e-002, -4.1655394e-002, -2.2462359e-002, -6.8363863e-002,  7.6694399e-002, -9.9639305e-001, -9.9343897e-001, -9.9089631e-001, -9.9660546e-001, -9.9392515e-001, -9.9141711e-001, -8.8123085e-001, -9.5238643e-001, -7.5320152e-001,  8.4641188e-001,  9.1025936e-001,  8.2428528e-001, -9.9110914e-001, -9.9997090e-001, -9.9995592e-001, -9.9988855e-001, -9.9649191e-001, -9.9456335e-001, -9.9387305e-001, -3.5436270e-001, -3.4961774e-001, -6.9257264e-001,  5.7594455e-004, -1.8982089e-002,  2.0087503e-001, -1.3319489e-001, -3.9633467e-002,  5.6549285e-002, -1.5229125e-002,  6.6569159e-002,  2.4885668e-001, -2.9127903e-001,  3.6934173e-001, -2.2340629e-001, -3.0713744e-001,  1.7127079e-001, -6.7813995e-001, -1.0162951e-001, -4.1681809e-002, -4.9140975e-002, -9.9556353e-001, -9.9590663e-001, -9.9443854e-001, -9.9525645e-001, -9.9595516e-001, -9.9391283e-001, -9.9753269e-001, -9.9776992e-001, -9.9478523e-001,  9.9588352e-001,  9.9673616e-001,  9.9705765e-001, -9.9608727e-001, -9.9997245e-001, -9.9998167e-001, -9.9995268e-001, -9.9406260e-001, -9.9630551e-001, -9.9283242e-001, -7.3731866e-001, -6.6653823e-001, -6.4538512e-001,  1.6429758e-001, -6.4724287e-003,  2.6194381e-001,  2.1010650e-001,  3.8581734e-002,  2.0816786e-001,  1.8714423e-001,  3.8185326e-002,  4.1175288e-001, -1.7534412e-001,  3.2071433e-001,  4.2368774e-001, -7.7227998e-002, -7.0380621e-003, -2.2326089e-001, -9.9135299e-001, -9.9320918e-001, -9.9366770e-001, -9.9145763e-001, -9.9691570e-001, -9.9135299e-001, -9.9986429e-001, -9.9261733e-001, -7.4777593e-001,  1.8958330e-001, -1.2099409e-001,  1.3726106e-001, -2.8229735e-001, -9.9135299e-001, -9.9320918e-001, -9.9366770e-001, -9.9145763e-001, -9.9691570e-001, -9.9135299e-001, -9.9986429e-001, -9.9261733e-001, -7.4777593e-001,  1.8958330e-001, -1.2099409e-001,  1.3726106e-001, -2.8229735e-001, -9.9393494e-001, -9.9870789e-001, -9.9822244e-001, -9.9815526e-001, -9.9298787e-001, -9.9393494e-001, -9.9991992e-001, -9.9708776e-001, -9.7610652e-001,  3.8497239e-001, -2.9205725e-001, -5.7060603e-002, -1.8595893e-001, -9.9146645e-001, -9.9580913e-001, -9.9585160e-001, -9.9408969e-001, -9.8125658e-001, -9.9146645e-001, -9.9993284e-001, -9.9762483e-001, -6.1101511e-001,  1.6453447e-001, -1.8379440e-001,  3.0163035e-002,  3.9799581e-002, -9.9612756e-001, -9.9741842e-001, -9.9719562e-001, -9.9715013e-001, -9.8532590e-001, -9.9612756e-001, -9.9997887e-001, -9.9682359e-001, -7.6824178e-001,  5.9385492e-001, -5.7847014e-001, -5.4970324e-002,  5.3886288e-002, -9.9731998e-001, -9.8683408e-001, -9.9128545e-001, -9.9900639e-001, -9.8669452e-001, -9.9064255e-001, -9.9820226e-001, -9.8872280e-001, -9.9126028e-001, -9.9921002e-001, -9.8670453e-001, -9.8873798e-001, -9.9405746e-001, -9.8935315e-001, -9.9288793e-001, -9.9481710e-001, -9.9999161e-001, -9.9978419e-001, -9.9981176e-001, -9.9506275e-001, -9.9165331e-001, -9.8740863e-001, -1.0000000e+000, -9.0474776e-001, -9.0357248e-001, -5.4838710e-001, -1.0000000e+000, -1.0000000e+000,  2.3571167e-001,  1.4119469e-001,  4.0083447e-001, -7.1538930e-001, -9.5699756e-001, -2.1345144e-001, -5.7055634e-001, -4.5759216e-001, -7.2243936e-001, -9.9999515e-001, -9.9998274e-001, -9.9996699e-001, -9.9992992e-001, -9.9995020e-001, -9.9994138e-001, -9.9993732e-001, -9.9998643e-001, -9.9999340e-001, -9.9995679e-001, -9.9996196e-001, -9.9995379e-001, -9.9999327e-001, -9.9994044e-001, -9.9972833e-001, -9.9995535e-001, -9.9988237e-001, -9.9982496e-001, -9.9970747e-001, -9.9984323e-001, -9.9979280e-001, -9.9986492e-001, -9.9978545e-001, -9.9984331e-001, -9.9975864e-001, -9.9981686e-001, -9.9978464e-001, -9.9981683e-001, -9.9980352e-001, -9.9979219e-001, -9.9988294e-001, -9.9990697e-001, -9.9974086e-001, -9.9952232e-001, -9.9982059e-001, -9.9971011e-001, -9.9980719e-001, -9.9992501e-001, -9.9971140e-001, -9.9979510e-001, -9.9980957e-001, -9.9986796e-001, -9.9590468e-001, -9.9070580e-001, -9.9201704e-001, -9.9733350e-001, -9.9321584e-001, -9.9198951e-001, -9.9563967e-001, -9.9258596e-001, -9.9019158e-001, -9.9831594e-001, -9.9284550e-001, -9.9392411e-001, -9.9798192e-001, -9.8983725e-001, -9.9338131e-001, -9.9424932e-001, -9.9996857e-001, -9.9988180e-001, -9.9986784e-001, -9.9269838e-001, -9.9232243e-001, -9.8808950e-001, -1.0000000e+000, -1.0000000e+000, -1.0000000e+000,  8.0000000e-002, -2.4000000e-001,  8.4000000e-001,  4.1521809e-001,  7.0929570e-002,  1.8992220e-001, -7.2477058e-001, -9.3740363e-001, -6.6918454e-001, -9.3728557e-001, -6.3617844e-001, -9.3617103e-001, -9.9999472e-001, -9.9998143e-001, -9.9996826e-001, -9.9992463e-001, -9.9994972e-001, -9.9992056e-001, -9.9990926e-001, -9.9997603e-001, -9.9998713e-001, -9.9995212e-001, -9.9994730e-001, -9.9990623e-001, -9.9998219e-001, -9.9992099e-001, -9.9992705e-001, -9.9996030e-001, -9.9986465e-001, -9.9983435e-001, -9.9979023e-001, -9.9985215e-001, -9.9990768e-001, -9.9997794e-001, -9.9995366e-001, -9.9983223e-001, -9.9981352e-001, -9.9992055e-001, -9.9990874e-001, -9.9984616e-001, -9.9985031e-001, -9.9982707e-001, -9.9985422e-001, -9.9991893e-001, -9.9970504e-001, -9.9950299e-001, -9.9980132e-001, -9.9997897e-001, -9.9983222e-001, -9.9991536e-001, -9.9963221e-001, -9.9980973e-001, -9.9986696e-001, -9.9983239e-001, -9.9435441e-001, -9.9381065e-001, -9.8994957e-001, -9.9709740e-001, -9.9315328e-001, -9.9197583e-001, -9.9606914e-001, -9.9361960e-001, -9.9022510e-001, -9.9666747e-001, -9.9482631e-001, -9.9374166e-001, -9.9766423e-001, -9.9726685e-001, -9.9828533e-001, -9.9376227e-001, -9.9998648e-001, -9.9996134e-001, -9.9991771e-001, -9.9367220e-001, -9.9433924e-001, -9.8839679e-001, -9.2037074e-001, -8.2721239e-001, -8.8888489e-001, -8.0000000e-001, -1.0000000e+000, -9.3103448e-001,  3.0375625e-001, -7.0266118e-002,  4.9921731e-002, -4.7649852e-001, -7.3888068e-001, -3.6625192e-001, -7.6491573e-001, -3.5011356e-001, -6.9637624e-001, -9.9999080e-001, -9.9997757e-001, -9.9997913e-001, -9.9996502e-001, -9.9995524e-001, -9.9995789e-001, -9.9997175e-001, -9.9998484e-001, -9.9998834e-001, -9.9997102e-001, -9.9995323e-001, -9.9997755e-001, -9.9998769e-001, -9.9996219e-001, -9.9994817e-001, -9.9999430e-001, -9.9998858e-001, -9.9998220e-001, -9.9999234e-001, -9.9997595e-001, -9.9996557e-001, -9.9998749e-001, -9.9996220e-001, -9.9998419e-001, -9.9998931e-001, -9.9997041e-001, -9.9996006e-001, -9.9998354e-001, -9.9993279e-001, -9.9996350e-001, -9.9994201e-001, -9.9997295e-001, -9.9998137e-001, -9.9987066e-001, -9.9994336e-001, -9.9996959e-001, -9.9992582e-001, -9.9993427e-001, -9.9995735e-001, -9.9995498e-001, -9.9992022e-001, -9.9997001e-001, -9.9369338e-001, -9.9294329e-001, -9.9105963e-001, -9.9537944e-001, -9.9404929e-001, -9.9369338e-001, -9.9990786e-001, -9.8980043e-001, -1.0000000e+000, -1.0000000e+000,  1.8582523e-001, -5.9866508e-001, -8.5698482e-001, -9.9834875e-001, -9.9807267e-001, -9.9727729e-001, -9.9787957e-001, -9.8656296e-001, -9.9834875e-001, -9.9998431e-001, -9.9516733e-001, -1.0000000e+000, -8.7301587e-001,  5.9000098e-001, -7.4050220e-001, -9.2684278e-001, -9.9589683e-001, -9.9632481e-001, -9.9551780e-001, -9.9756071e-001, -9.9979514e-001, -9.9589683e-001, -9.9997647e-001, -9.9381239e-001, -1.0000000e+000, -7.4358974e-001,  1.8641558e-001, -7.4486698e-001, -9.2980063e-001, -9.9734550e-001, -9.9730116e-001, -9.9701055e-001, -9.9724602e-001, -9.9263674e-001, -9.9734550e-001, -9.9998881e-001, -9.9563466e-001, -1.0000000e+000, -1.0000000e+000,  3.8443712e-001, -4.6974289e-001, -7.4143520e-001,  1.5758438e-001, -3.3487056e-002, -3.5089342e-001,  3.4314576e-001, -6.8410997e-001,  3.0082171e-001, -6.4263125e-002\n",
      "\n",
      "**Prediction:** WALKING\n",
      "\n",
      "The data point is classified as 'WALKING' because the values of the features are within the typical range for walking activities.\n",
      "\n",
      "**Data Point 2:**\n",
      "2.  2.7981772e-001, -1.0396061e-002, -1.1320248e-001, -9.8493079e-001, -9.5923068e-001, -9.6438621e-001, -9.8814348e-001, -9.6140709e-001, -9.6889831e-001, -9.2332341e-001, -5.3573948e-001, -7.9493686e-001,  8.3627600e-001,  6.7105384e-001,  8.2490743e-001, -9.7457954e-001, -9.9982150e-001, -9.9944614e-001, -9.9890324e-001, -9.9179229e-001, -9.6796403e-001, -9.7939467e-001, -3.8500446e-001, -2.5871353e-001, -4.9384805e-001,  1.5975983e-001,  2.4844434e-002,  6.8426583e-002,  4.2134816e-001, -1.6440715e-001,  1.2244231e-001,  2.9281656e-002,  1.1233449e-001,  1.6033832e-001, -1.0601435e-001, -2.2134454e-002,  1.6820547e-001,  1.5537276e-001, -3.5043202e-001,  2.1294114e-001,  9.7327809e-001, -1.3761653e-001,  3.8872702e-002, -9.9902909e-001, -9.8490733e-001, -9.8913861e-001, -9.9894729e-001, -9.8531227e-001, -9.8912165e-001,  8.9862574e-001, -1.5681833e-001,  3.1735989e-002,  9.9278574e-001, -1.1365364e-001,  3.8513083e-002, -5.6959576e-001,  9.2565287e-001, -9.7241923e-001, -9.9780880e-001, -9.9886918e-001, -9.8635371e-001, -9.8897762e-001, -1.0000000e+000, -1.0000000e+000, -6.9496821e-001, -7.5743325e-002,  2.5010905e-001, -4.2635895e-001,  6.0426621e-001, -5.2400571e-001,  5.0527952e-001, -5.1851593e-001,  5.4528529e-001, -5.8025055e-001,  5.9512624e-001, -6.0954099e-001,  6.2066287e-001,  9.4167814e-001, -8.0298700e-001, -6.8118740e-001,  7.4634480e-002, -2.7442520e-002,  7.9791098e-003, -9.7657193e-001, -9.7306215e-001, -9.8131878e-001, -9.7760271e-001, -9.6787989e-001, -9.7998275e-001, -9.7858807e-001, -9.8581431e-001, -9.7482632e-001,  9.7540763e-001,  9.7728776e-001,  9.8129428e-001, -9.7669505e-001, -9.9956779e-001, -9.9937612e-001, -9.9955171e-001, -9.7994133e-001, -9.6581864e-001, -9.7929405e-001, -5.2014090e-001, -5.7827892e-001, -6.1495502e-001, -6.8260735e-002,  1.4665241e-001,  1.1994050e-001,  3.0790259e-001, -1.9593609e-001,  4.2691513e-002,  5.7983486e-002,  1.8865176e-001,  7.4910159e-002, -4.2750774e-002, -1.1204253e-001,  8.4160319e-002,  1.9567696e-001, -1.2285096e-001,  9.6927449e-002, -1.6789285e-002, -8.0774312e-002,  1.2788896e-001, -9.8366942e-001, -9.5989187e-001, -9.5371276e-001, -9.8503729e-001, -9.6178852e-001, -9.5543488e-001, -8.6212870e-001, -9.3126227e-001, -7.0828643e-001,  8.3518344e-001,  8.8814877e-001,  8.1385036e-001, -9.5784012e-001, -9.9977477e-001, -9.9910070e-001, -9.9816019e-001, -9.8645110e-001, -9.6366311e-001, -9.6507526e-001, -1.3445327e-002, -1.6020144e-001,  1.9765695e-001, -2.3214792e-001,  2.1292587e-001, -2.3105567e-002,  4.8191470e-002, -3.6109788e-001,  2.9936245e-001, -2.2481784e-001,  2.5879739e-001,  1.1777313e-002,  4.8813054e-003, -1.9948926e-002,  1.9794972e-002, -2.8386996e-001, -1.7510335e-001, -5.0303268e-001, -1.0379423e-001, -4.0720764e-002, -4.8389537e-002, -9.7966344e-001, -9.8176957e-001, -9.6994518e-001, -9.8078831e-001, -9.8168503e-001, -9.7003540e-001, -9.7581740e-001, -9.8439008e-001, -9.7313396e-001,  9.8149111e-001,  9.8647874e-001,  9.7929974e-001, -9.7948272e-001, -9.9971281e-001, -9.9978986e-001, -9.9937868e-001, -9.8417270e-001, -9.8129338e-001, -9.7112633e-001, -3.8155530e-001, -1.8133839e-001, -2.1312504e-001, -7.7769812e-002,  5.8704894e-002,  2.3141204e-001, -1.6110248e-001, -2.7879283e-001,  2.1513908e-001,  5.3564413e-002, -2.2928381e-001,  1.7194523e-001, -2.6022138e-002,  3.4519123e-001, -4.3028860e-001, -2.5051932e-001,  2.0338099e-001, -5.1644909e-001, -9.7556248e-001, -9.6792516e-001, -9.6924305e-001, -9.7051693e-001, -9.9455771e-001, -9.7556248e-001, -9.9930537e-001, -9.7022735e-001, -3.5795456e-001, -1.0862183e-001, -3.7665365e-003,  1.9554898e-001, -9.6706709e-002, -9.\n",
      "\n",
      " Answer from llama3.1-70b: \n",
      "Based on the given data, I predict the activities as follows:\n",
      "\n",
      "1. WALKING\n",
      "2. WALKING\n",
      "3. WALKING_UPSTAIRS\n",
      "4. WALKING_DOWNSTAIRS\n",
      "5. WALKING\n",
      "6. WALKING\n",
      "\n",
      "The reasoning behind these predictions is based on the analysis of the features provided. Here's a brief explanation for each prediction:\n",
      "\n",
      "1. The data shows a moderate level of acceleration and jerk in the X, Y, and Z axes, which is consistent with walking. The mean and standard deviation of the acceleration and jerk are also within the range of walking.\n",
      "2. Similar to the first data point, the second data point also shows a moderate level of acceleration and jerk in the X, Y, and Z axes, which is consistent with walking.\n",
      "3. The data shows a higher level of acceleration and jerk in the X and Y axes compared to the Z axis, which is consistent with walking upstairs. The mean and standard deviation of the acceleration and jerk are also higher than the first two data points, which suggests a more energetic activity.\n",
      "4. The data shows a lower level of acceleration and jerk in the X and Y axes compared to the Z axis, which is consistent with walking downstairs. The mean and standard deviation of the acceleration and jerk are also lower than the first two data points, which suggests a less energetic activity.\n",
      "5. The data shows a moderate level of acceleration and jerk in the X, Y, and Z axes, which is consistent with walking. The mean and standard deviation of the acceleration and jerk are also within the range of walking.\n",
      "6. Similar to the first data point, the sixth data point also shows a moderate level of acceleration and jerk in the X, Y, and Z axes, which is consistent with walking.\n",
      "\n",
      "Note that these predictions are based on a simple analysis of the features provided and may not be accurate in all cases. A more robust model would require a larger dataset and more advanced machine learning techniques.\n"
     ]
    }
   ],
   "source": [
    "features_row = 0\n",
    "with open('TestDataset_561.csv', 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    rows = list(reader)\n",
    "\n",
    "if features_row < len(rows):\n",
    "    row = rows[features_row][:-2]\n",
    "    features_string = ', '.join(row)\n",
    "else:\n",
    "    print(f\"Error in features reading\")\n",
    "\n",
    "test_rows = [10, 50, 70, 90, 120, 150] #STANDING, SITTING, LAYING, WALKING, WALKING_DOWNSTAIRS, WALKING_UPSTAIRS\n",
    "test_rows_string = []\n",
    "for test_rown in test_rows:\n",
    "    with open('TestDataset_561.csv', 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    if test_rown < len(rows):\n",
    "        row = rows[test_rown][:-2]\n",
    "        test_rown_string = ', '.join(row)\n",
    "        test_rows_string.append(test_rown_string)\n",
    "    else:\n",
    "        print(f\"Error in test row reading\")\n",
    "\n",
    "query = f\"\"\"\n",
    "* You are a activity recognition model. \n",
    "* Your task is to analyze the given data in form of certain features and classify the activity as 'WALKING', 'WALKING_DOWNSTAIRS' or 'WALKING_UPSTAIRS'. \n",
    "* The data is normalized between [-1, 1]\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "* The complete list of features is as follows:\n",
    "{features_string}\n",
    "\n",
    "\n",
    "Analyze the following data and predict the activities:\n",
    "1. {test_rows_string[0]}\n",
    "2. {test_rows_string[1]}\n",
    "3. {test_rows_string[2]}\n",
    "4. {test_rows_string[3]}\n",
    "5. {test_rows_string[4]}\n",
    "6. {test_rows_string[5]}\n",
    "\"\"\" \n",
    "\n",
    "model_name = \"llama3.1-8b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"Answer from llama3.1-8b: \")\n",
    "print(answer.content)\n",
    "\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"\\n Answer from llama3.1-70b: \")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from llama3.1-8b: \n",
      "Based on the provided data, I will analyze the activities and predict the labels.\n",
      "\n",
      "**Data 1:**\n",
      "2.7574570e-001, -1.0371994e-002, -9.9775890e-002, -9.9837313e-001, -9.8693291e-001, -9.9102190e-001, -9.9866291e-001, -9.8713965e-001, -9.9108432e-001, -9.4376125e-001, -5.6428961e-001, -8.1432563e-001,  8.4975268e-001,  6.8922983e-001,  8.4737582e-001, -9.9110378e-001, -9.9999154e-001, -9.9983492e-001, -9.9973485e-001, -9.9859886e-001, -9.8980896e-001, -9.8928972e-001, -7.6858336e-001, -4.3323793e-001, -3.9328675e-001,  3.9409003e-001, -1.7537723e-001,  1.3718364e-001,  1.8434982e-001,  8.3437153e-002, -2.1274865e-002,  3.8584767e-002, -6.5816959e-002,  4.2912522e-001, -2.7979818e-001,  1.5752764e-001, -5.2535204e-002,  1.2899289e-002, -7.8381560e-002,  2.5741515e-001,  9.2417336e-001, -3.1759660e-001,  1.2458390e-001, -9.9800172e-001, -9.8939331e-001, -9.9196835e-001, -9.9791812e-001, -9.8990488e-001, -9.9261060e-001,  8.5020163e-001, -3.3207944e-001,  1.1805617e-001,  9.4442809e-001, -2.8847057e-001,  1.2594389e-001,  5.3761724e-002,  7.9725941e-001, -8.2692917e-001, -9.7200939e-001, -9.9787221e-001, -9.9142466e-001, -9.9400663e-001, -1.0000000e+000, -1.0000000e+000, -7.8618011e-001, -4.4300790e-001,  4.6643649e-001, -4.8988673e-001,  5.1345808e-001, -2.7782560e-001,  2.0762595e-001, -1.8315639e-001,  1.7982801e-001, -3.2368703e-001,  3.3180210e-001, -3.3983222e-001,  3.4544263e-001, -7.8945759e-001, -7.1051977e-001,  9.8382509e-001,  7.7145726e-002,  1.8711721e-002,  1.1466155e-002, -9.9636877e-001, -9.9148028e-001, -9.9279344e-001, -9.9610539e-001, -9.8879884e-001, -9.8980846e-001, -9.9435966e-001, -9.9784205e-001, -9.9586157e-001,  9.9728549e-001,  9.9351841e-001,  9.9619136e-001, -9.9392766e-001, -9.9996864e-001, -9.9988165e-001, -9.9986763e-001, -9.9368582e-001, -9.8495078e-001, -9.8172573e-001, -8.3927424e-001, -7.7938980e-001, -7.7317959e-001,  3.2097169e-001,  1.2056967e-001,  2.8412716e-001,  2.1790389e-001,  1.0240066e-001,  1.8176848e-001,  1.7987603e-001,  2.5780266e-001,  3.3143965e-001, -3.8905097e-002,  7.2331479e-002,  2.3502918e-001,  1.8743765e-002,  2.5985266e-002, -4.1655394e-002, -2.2462359e-002, -6.8363863e-002,  7.6694399e-002, -9.9639305e-001, -9.9343897e-001, -9.9089631e-001, -9.9660546e-001, -9.9392515e-001, -9.9141711e-001, -8.8123085e-001, -9.5238643e-001, -7.5320152e-001,  8.4641188e-001,  9.1025936e-001,  8.2428528e-001, -9.9110914e-001, -9.9997090e-001, -9.9995592e-001, -9.9988855e-001, -9.9649191e-001, -9.9456335e-001, -9.9387305e-001, -3.5436270e-001, -3.4961774e-001, -6.9257264e-001,  5.7594455e-004, -1.8982089e-002,  2.0087503e-001, -1.3319489e-001, -3.9633467e-002,  5.6549285e-002, -1.5229125e-002,  6.6569159e-002,  2.4885668e-001, -2.9127903e-001,  3.6934173e-001, -2.2340629e-001, -3.0713744e-001,  1.7127079e-001, -6.7813995e-001, -1.0162951e-001, -4.1681809e-002, -4.9140975e-002, -9.9556353e-001, -9.9590663e-001, -9.9443854e-001, -9.9525645e-001, -9.9595516e-001, -9.9391283e-001, -9.9753269e-001, -9.9776992e-001, -9.9478523e-001,  9.9588352e-001,  9.9673616e-001,  9.9705765e-001, -9.9608727e-001, -9.9997245e-001, -9.9998167e-001, -9.9995268e-001, -9.9406260e-001, -9.9630551e-001, -9.9283242e-001, -7.3731866e-001, -6.6653823e-001, -6.4538512e-001,  1.6429758e-001, -6.4724287e-003,  2.6194381e-001,  2.1010650e-001,  3.8581734e-002,  2.0816786e-001,  1.8714423e-001,  3.8185326e-002,  4.1175288e-001, -1.7534412e-001,  3.2071433e-001,  4.2368774e-001, -7.7227998e-002, -7.0380621e-003, -2.2326089e-001, -9.9135299e-001, -9.9320918e-001, -9.9366770e-001, -9.9145763e-001, -9.9691570e-001, -9.9135299e-001, -9.9986429e-001, -9.9261733e-001, -7.4777593e-001,  1.8958330e-001, -1.2099409e-001,  1.3726106e-001, -2.8229735e-001, -9.9135299e-001, -9.9320918e-001, -9.9366770e-001, -9.9145763e-001, -9.9691570e-001, -9.9135299e-001, -9.9986429e-001, -9.9261733e-001, -7.4777593e-001,  1.8958330e-001, -1.2099409e-001,  1.3726106e-001, -2.8229735e-001, -9.9393494e-001, -9.9870789e-001, -9.9822244e-001, -9.9815526e-001, -9.9298787e-001, -9.9393494e-001, -9.9991992e-001, -9.9708776e-001, -9.7610652e-001,  3.8497239e-001, -2.9205725e-001, -5.7060603e-002, -1.8595893e-001, -9.9146645e-001, -9.9580913e-001, -9.9585160e-001, -9.9408969e-001, -9.8125658e-001, -9.9146645e-001, -9.9993284e-001, -9.9762483e-001, -6.1101511e-001,  1.6453447e-001, -1.8379440e-001,  3.0163035e-002,  3.9799581e-002, -9.9612756e-001, -9.9741842e-001, -9.9719562e-001, -9.9715013e-001, -9.8532590e-001, -9.9612756e-001, -9.9997887e-001, -9.9682359e-001, -7.6824178e-001,  5.9385492e-001, -5.7847014e-001, -5.4970324e-002,  5.3886288e-002, -9.9731998e-001, -9.8683408e-001, -9.9128545e-001, -9.9900639e-001, -9.8669452e-001, -9.9064255e-001, -9.9820226e-001, -9.8872280e-001, -9.9126028e-001, -9.9921002e-001, -9.8670453e-001, -9.8873798e-001, -9.9405746e-001, -9.8935315e-001, -9.9288793e-001, -9.9481710e-001, -9.9999161e-001, -9.9978419e-001, -9.9981176e-001, -9.9506275e-001, -9.9165331e-001, -9.8740863e-001, -1.0000000e+000, -9.0474776e-001, -9.0357248e-001, -5.4838710e-001, -1.0000000e+000, -1.0000000e+000,  2.3571167e-001,  1.4119469e-001,  4.0083447e-001, -7.1538930e-001, -9.5699756e-001, -2.1345144e-001, -5.7055634e-001, -4.5759216e-001, -7.2243936e-001, -9.9999515e-001, -9.9998274e-001, -9.9996699e-001, -9.9992992e-001, -9.9995020e-001, -9.9994138e-001, -9.9993732e-001, -9.9998643e-001, -9.9999340e-001, -9.9995679e-001, -9.9996196e-001, -9.9995379e-001, -9.9999327e-001, -9.9994044e-001, -9.9972833e-001, -9.9995535e-001, -9.9988237e-001, -9.9982496e-001, -9.9970747e-001, -9.9984323e-001, -9.9979280e-001, -9.9986492e-001, -9.9978545e-001, -9.9984331e-001, -9.9975864e-001, -9.9981686e-001, -9.9978464e-001, -9.9981683e-001, -9.9980352e-001, -9.9979219e-001, -9.9988294e-001, -9.9990697e-001, -9.9974086e-001, -9.9952232e-001, -9.9982059e-001, -9.9971011e-001, -9.9980719e-001, -9.9992501e-001, -9.9971140e-001, -9.9979510e-001, -9.9980957e-001, -9.9986796e-001, -9.9590468e-001, -9.9070580e-001, -9.9201704e-001, -9.9733350e-001, -9.9321584e-001, -9.9198951e-001, -9.9563967e-001, -9.9258596e-001, -9.9019158e-001, -9.9831594e-001, -9.9284550e-001, -9.9392411e-001, -9.9798192e-001, -9.8983725e-001, -9.9338131e-001, -9.9424932e-001, -9.9996857e-001, -9.9988180e-001, -9.9986784e-001, -9.9269838e-001, -9.9232243e-001, -9.8808950e-001, -1.0000000e+000, -1.0000000e+000, -1.0000000e+000,  8.0000000e-002, -2.4000000e-001,  8.4000000e-001,  4.1521809e-001,  7.0929570e-002,  1.8992220e-001, -7.2477058e-001, -9.3740363e-001, -6.6918454e-001, -9.3728557e-001, -6.3617844e-001, -9.3617103e-001, -9.9999472e-001, -9.9998143e-001, -9.9996826e-001, -9.9992463e-001, -9.9994972e-001, -9.9992056e-001, -9.9990926e-001, -9.9997603e-001, -9.9998713e-001, -9.9995212e-001, -9.9994730e-001, -9.9990623e-001, -9.9998219e-001, -9.9992099e-001, -9.9992705e-001, -9.9996030e-001, -9.9986465e-001, -9.9983435e-001, -9.9979023e-001, -9.9985215e-001, -9.9990768e-001, -9.9997794e-001, -9.9995366e-001, -9.9983223e-001, -9.9981352e-001, -9.9992055e-001, -9.9990874e-001, -9.9984616e-001, -9.9985031e-001, -9.9982707e-001, -9.9985422e-001, -9.9991893e-001, -9.9970504e-001, -9.9950299e-001, -9.9980132e-001, -9.9997897e-001, -9.9983222e-001, -9.9991536e-001, -9.9963221e-001, -9.9980973e-001, -9.9986696e-001, -9.9983239e-001, -9.9435441e-001, -9.9381065e-001, -9.8994957e-001, -9.9709740e-001, -9.9315328e-001, -9.9197583e-001, -9.9606914e-001, -9.9361960e-001, -9.9022510e-001, -9.9666747e-001, -9.9482631e-001, -9.9374166e-001, -9.9766423e-001, -9.9726685e-001, -9.9828533e-001, -9.9376227e-001, -9.9998648e-001, -9.9996134e-001, -9.9991771e-001, -9.9367220e-001, -9.9433924e-001, -9.8839679e-001, -9.2037074e-001, -8.2721239e-001, -8.8888489e-001, -8.0000000e-001, -1.0000000e+000, -9.3103448e-001,  3.0375625e-001, -7.0266118e-002,  4.9921731e-002, -4.7649852e-001, -7.3888068e-001, -3.6625192e-001, -7.6491573e-001, -3.5011356e-001, -6.9637624e-001, -9.9999080e-001, -9.9997757e-001, -9.9997913e-001, -9.9996502e-001, -9.9995524e-001, -9.9995789e-001, -9.9997175e-001, -9.9998484e-001, -9.9998834e-001, -9.9997102e-001, -9.9995323e-001, -9.9997755e-001, -9.9998769e-001, -9.9996219e-001, -9.9994817e-001, -9.9999430e-001, -9.9998858e-001, -9.9998220e-001, -9.9999234e-001, -9.9997595e-001, -9.9996557e-001, -9.9998749e-001, -9.9996220e-001, -9.9998419e-001, -9.9998931e-001, -9.9997041e-001, -9.9996006e-001, -9.9998354e-001, -9.9993279e-001, -9.9996350e-001, -9.9994201e-001, -9.9997295e-001, -9.9998137e-001, -9.9987066e-001, -9.9994336e-001, -9.9996959e-001, -9.9992582e-001, -9.9993427e-001, -9.9995735e-001, -9.9995498e-001, -9.9992022e-001, -9.9997001e-001, -9.9369338e-001, -9.9294329e-001, -9.9105963e-001, -9.9537944e-001, -9.9404929e-001, -9.9369338e-001, -9.9990786e-001, -9.8980043e-001, -1.0000000e+000, -1.0000000e+000,  1.8582523e-001, -5.9866508e-001, -8.5698482e-001, -9.9834875e-001, -9.9807267e-001, -9.9727729e-001, -9.9787957e-001, -9.8656296e-001, -9.9834875e-001, -9.9998431e-001, -9.9516733e-001, -1.0000000e+000, -8.7301587e-001,  5.9000098e-001, -7.4050220e-001, -9.2684278e-001, -9.9589683e-001, -9.9632481e-001, -9.9551780e-001, -9.9756071e-001, -9.9979514e-001, -9.9589683e-001, -9.9997647e-001, -9.9381239e-001, -1.0000000e+000, -7.4358974e-001,  1.8641558e-001, -7.4486698e-001, -9.2980063e-001, -9.9734550e-001, -9.9730116e-001, -9.9701055e-001, -9.9724602e-001, -9.9263674e-001, -9.9734550e-001, -9.9998881e-001, -9.9563466e-001, -1.0000000e+000, -1.0000000e+000,  3.8443712e-001, -4.6974289e-001, -7.4143520e-001,  1.5758438e-001, -3.3487056e-002, -3.5089342e-001,  3.4314576e-001, -6.8410997e-001,  3.0082171e-001, -6.4263125e-002\n",
      "\n",
      "**Predicted Label:** WALKING\n",
      "\n",
      "**Data 2:**\n",
      "2.7981772e-001, -1.0396061e-002, -1.1320248e-001, -9.8493079e-001, -9.5923068e-001, -9.6438621e-001, -9.8814348e-001, -9.6140709e-001, -9.6889831e-001, -9.2332341e-001, -5.3573948e-001, -7.9493686e-001,  8.3627600e-001,  6.7105384e-001,  8.2490743e-001, -9.7457954e-001, -9.9982150e-001, -9.9944614e-001, -9.9890324e-001, -9.9179229e-001, -9.6796403e-001, -9.7939467e-001, -3.8500446e-001, -2.5871353e-001, -4.9384805e-001,  1.5975983e-001,  2.4844434e-002,  6.8426583e-002,  4.2134816e-001, -1.6440715e-001,  1.2244231e-001,  2.9281656e-002,  1.1233449e-001,  1.6033832e-001, -1.0601435e-001, -2.2134454e-002,  1.6820547e-001,  1.5537276e-001, -3.5043202e-001,  2.1294114e-001,  9.7327809e-001, -1.3761653e-001,  3.8872702e-002, -9.9902909e-001, -9.8490733e-001, -9.8913861e-001, -9.9894729e-001, -9.8531227e-001, -9.8912165e-001,  8.9862574e-001, -1.5681833e-001,  3.1735989e-002,  9.9278574e-001, -1.1365364e-001,  3.8513083e-002, -5.6959576e-001,  9.2565287e-001, -9.7241923e-001, -9.9780880e-001, -9.9886918e-001, -9.8635371e-001, -9.8897762e-001, -1.0000000e+000, -1.0000000e+000, -6.9496821e-001, -7.5743325e-002,  2.5010905e-001, -4.2635895e-001,  6.0426621e-001, -5.2400571e-001,  5.0527952e-001, -5.1851593e-001,  5.4528529e-001, -5.8025055e-001,  5.9512624e-001, -6.0954099e-001,  6.2066287e-001,  9.4167814e-001, -8.0298700e-001, -6.8118740e-001,  7.4634480e-002, -2.7442520e-002,  7.9791098e-003, -9.7657193e-001, -9.7306215e-001, -9.8131878e-001, -9.7760271e-001, -9.6787989e-001, -9.7998275e-001, -9.7858807e-001, -9.8581431e-001, -9.7482632e-001,  9.7540763e-001,  9.7728776e-001,  9.8129428e-001, -9.7669505e-001, -9.9956779e-001, -9.9937612e-001, -9.9955171e-001, -9.7994133e-001, -9.6581864e-001, -9.7929405e-001, -5.2014090e-001, -5.7827892e-001, -6.1495502e-001, -6.8260735e-002,  1.4665241e-001,  1.1994050e-001,  3.0790259e-001, -1.9593609e-001,  4.2691513e-002,  5.7983486e-002,  1.8865176e-001,  7.4910159e-002, -4.2750774e-002, -1.1204253e-001,  8.4160319e-002,  1.9567696e-001, -1.2285096e-001,  9.6927449e-002, -1.6789285e-002, -8.0774312e-002,  1.2788896e-001, -9.8366942e-001, -9.5989187e-001, -9.5371276e-001, -9.8503729e-001, -9.6178852e-001, -9.5543488e-001, -8.6212870e-001, -9.3126227e-001, -7.0828643e-001,  8.3518344e-001,  8.8814877e-001,  8.1385036e-001, -9.5784012e-001, -9.9977477e-001, -9.9910070e-001, -9.9816019e-001, -9.8645110e-001, -9.6366311e-001, -9.6507526e-001, -1.3445327e-002, -1.6020144e-001,  1.9765695e-001, -2.3214792e-001,  2.1292587e-001, -2.3105567e-002,  4.8191470e-002, -3.6109788e-001,  2.9936245e-001, -2.2481784e-001,  2.5879739e-001,  1.1777313e-002,  4.8813054e-003, -1.9948926e-002,  1.9794972e-002, -2.8386996e-001, -1.7510335e-001, -5.0303268e-001, -1.0379423e-001, -4.0720764e-002, -4.8389537e-002, -9.7966344e-001, -9.8176957e-001, -9.6994518e-001, -9.8078831e-001, -9.8168503e-001, -9.7003540e-001, -9.7581740e-001, -9.8439008e-001, -9.7313396e-001,  9.8149111e-001,  9.8647874e-001,  9.7929974e-001, -9.7948272e-001, -9.9971281e-001, -9.9978986e-001, -9.9937868e-001, -9.8417270e-001, -9.8129338e-001, -9.7112633e-001, -3.8155530e-001, -1.8133839e-001, -2.1312504e-001, -7.7769812e-002,  5.8704894e-002,  2.3141204e-001, -1.6110248e-001, -2.7879283e-001,  2.1513908e-001,  5.3564413e-002, -2.2928381e-001,  1.7194523e-001, -2.6022138e-002,  3.4519123e-001, -4.3028860e-001, -2.5051932e-001,  2.0338099e-001, -5.1644909e-001, -9.7556248e-001, -9.6792516e-001, -9.6924305e-001, -9.7051693e-001, -9.9455771e-001, -9.7556248e-001, -9.9930537e-001, -9.7022735e-001, -3.5795456e-001, -1.0862183e-001, -3.7665365e-003,  1.9554898e-001, -9.6706709e-002, -9.7556248e-001, -9.6792516e-001, -9.6924305e-001, -9.7051693e-001, -9.9455771e-001, -9.7556248e-001, -9\n",
      "\n",
      " Answer from llama3.1-70b: \n",
      "Based on the given data, I predict the activities as follows:\n",
      "\n",
      "1. WALKING\n",
      "2. WALKING\n",
      "3. WALKING_DOWNSTAIRS\n",
      "4. WALKING_DOWNSTAIRS\n",
      "5. WALKING_UPSTAIRS\n",
      "6. WALKING_UPSTAIRS\n",
      "\n",
      "The reasoning behind these predictions is based on the patterns and trends observed in the given data. For example, the first two data points have similar patterns and trends, which are consistent with walking. The third and fourth data points have patterns and trends that are consistent with walking downstairs. The fifth and sixth data points have patterns and trends that are consistent with walking upstairs.\n",
      "\n",
      "It's worth noting that these predictions are based on a limited amount of data and may not be accurate for all cases. A more robust model would require a larger dataset and more advanced machine learning techniques to accurately predict the activities.\n"
     ]
    }
   ],
   "source": [
    "features_row = 0\n",
    "with open('TestDataset_561.csv', 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    rows = list(reader)\n",
    "\n",
    "if features_row < len(rows):\n",
    "    row = rows[features_row][:-2]\n",
    "    features_string = ', '.join(row)\n",
    "else:\n",
    "    print(f\"Error in features reading\")\n",
    "\n",
    "#This data will be given as examples for the LLM to learn and give better predictions\n",
    "train_rows = [[1990, 2160], [2670, 2840], [2410, 3590]]\n",
    "train_labels = [\"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]\n",
    "train_string = \"\"\n",
    "for i in range(len(train_rows)):\n",
    "    with open('Dataset_561.csv', 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        rows = list(reader)\n",
    "    for rown in train_rows[i]:\n",
    "        if (rown < len(rows)):\n",
    "            row = rows[rown][:-2]\n",
    "            train_rown_string = ', '.join(row)\n",
    "            train_string = train_string + '\\n' + train_rown_string + ': ' + train_labels[i]\n",
    "        else:\n",
    "            print(\"Error in train row reading\")\n",
    "\n",
    "test_rows = [10, 50, 70, 90, 120, 150] #STANDING, SITTING, LAYING, WALKING, WALKING_DOWNSTAIRS, WALKING_UPSTAIRS\n",
    "test_rows_string = []\n",
    "for test_rown in test_rows:\n",
    "    with open('TestDataset_561.csv', 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    if test_rown < len(rows):\n",
    "        row = rows[test_rown][:-2]\n",
    "        test_rown_string = ', '.join(row)\n",
    "        test_rows_string.append(test_rown_string)\n",
    "    else:\n",
    "        print(f\"Error in test row reading\")\n",
    "\n",
    "query = f\"\"\"\n",
    "* You are a activity recognition model. \n",
    "* Your task is to analyze the given data in form of certain features and classify the activity as 'WALKING', 'WALKING_DOWNSTAIRS' or 'WALKING_UPSTAIRS'. \n",
    "* The data is normalized between [-1, 1]\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "* The complete list of features is as follows:\n",
    "{features_string}\n",
    "\n",
    "A few examples are as follows:\n",
    "{train_string}\n",
    "\n",
    "Analyze the following data and predict the activities:\n",
    "1. {test_rows_string[0]}\n",
    "2. {test_rows_string[1]}\n",
    "3. {test_rows_string[2]}\n",
    "4. {test_rows_string[3]}\n",
    "5. {test_rows_string[4]}\n",
    "6. {test_rows_string[5]}\n",
    "\"\"\" \n",
    "model_name = \"llama3.1-8b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"Answer from llama3.1-8b: \")\n",
    "print(answer.content)\n",
    "\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"\\n Answer from llama3.1-70b: \")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model with random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from llama3.1-8b: \n",
      "Based on the given data, I will analyze and predict the activities.\n",
      "\n",
      "**Data 1:**\n",
      "The data is:\n",
      "[ 0.59123672  0.35350348 -0.77343102 -0.50677985  0.74054349  0.07768547\n",
      "  0.0089077  -0.29573961  0.40446002  0.61890575  0.17020325  0.35742974\n",
      " -0.36427093  0.96938591 -0.16340231  0.42793073 -0.95093103  0.92171122\n",
      "  0.93168836  0.91287292 -0.60621623 -0.67451401 -0.45376676 -0.16655504\n",
      "  0.58293793 -0.62396803 -0.50036729 -0.50149461  0.16017251  0.20727455\n",
      " -0.61359754  0.23671121 -0.48184388  0.43946153  0.98322993  0.6280201\n",
      "  0.28271208  0.50726997  0.97818728 -0.40108369  0.19267865 -0.84991435\n",
      " -0.38863946  0.17465254  0.9551787  -0.84605211  0.4778368   0.65142686\n",
      "  0.892016   -0.90817933 -0.85114402  0.25970905  0.02111102  0.15016561\n",
      " -0.36357625  0.70385034 -0.51774498  0.28889535 -0.16313127  0.94631692\n",
      " -0.2604338  -0.25377385  0.00355832 -0.47267617 -0.86381615  0.79452095\n",
      " -0.49483778 -0.08845178  0.38745728  0.69506822 -0.65083075  0.27295377\n",
      "  0.82649611  0.05016494  0.43749768  0.16307097  0.11719546 -0.17003165\n",
      "  0.41227229 -0.99160505  0.37662642  0.74204697  0.37466855  0.04551602\n",
      "  0.55013395 -0.94464347 -0.2035411   0.01525598 -0.62605679  0.45618901\n",
      " -0.83768912 -0.251596   -0.95616737  0.75890182  0.19102877 -0.44485312\n",
      " -0.27620597  0.64574134  0.14870572 -0.14656714 -0.84931317  0.76160241\n",
      " -0.17812868 -0.0290872  -0.96904697  0.13231195 -0.46655933  0.42806947\n",
      "  0.6193804  -0.30672623 -0.60748112  0.5994784  -0.00591698 -0.49064561\n",
      " -0.49347931 -0.23780151  0.2836718  -0.65191027 -0.65493566 -0.95342661\n",
      " -0.5491047  -0.74030759  0.32654182 -0.20700176  0.96735271 -0.24565462\n",
      " -0.71042703 -0.52487384  0.10922961  0.04225948  0.93193769 -0.19976765\n",
      " -0.90261097  0.19103237  0.02489969 -0.68820256 -0.89188952  0.4597779\n",
      " -0.06675507 -0.67346936 -0.71248302  0.600118    0.33798807  0.71042833\n",
      "  0.03139251  0.59692545  0.3027074  -0.76021861  0.03384109 -0.20672228\n",
      "  0.09272072  0.06139083  0.95231004  0.00331942  0.18317555 -0.94426559\n",
      " -0.73463179  0.69485581 -0.61821146  0.2960695  -0.11957934 -0.56251657\n",
      " -0.35217555 -0.8775149   0.63586843 -0.03374015 -0.40417435 -0.35822368\n",
      " -0.63248803  0.47540299  0.68338479 -0.20765414  0.35901923  0.93149982\n",
      "  0.0231503   0.15453104 -0.61456     0.8997487  -0.25164028  0.43623752\n",
      "  0.446131    0.20605966 -0.53691879  0.3787637   0.43863083 -0.94942441\n",
      " -0.09320401 -0.95479608  0.52006123 -0.5121818   0.03101153 -0.90194977\n",
      " -0.13523315 -0.02321935 -0.93327077 -0.42467866  0.3499155   0.96869099\n",
      " -0.48098798  0.55730928 -0.59962977  0.58861907  0.88328122 -0.18864806\n",
      " -0.35531717  0.25743175 -0.14782979  0.58965083  0.28873514  0.5199626\n",
      " -0.56712777  0.88164313 -0.22143746 -0.41043484 -0.4335966   0.50842717\n",
      " -0.89782808 -0.56468975 -0.98177414  0.18240566  0.22048747 -0.32110836\n",
      "  0.76635181  0.84083471  0.41758795 -0.79300694  0.1714943   0.54280922\n",
      "  0.88952227 -0.56936159 -0.70987262 -0.79104798 -0.95861853 -0.69154142\n",
      "  0.77046947  0.20541272  0.17746003  0.53332973  0.84493137  0.84120685\n",
      "  0.09749799 -0.89253691 -0.78878915  0.7967554  -0.84482095  0.40211657\n",
      "  0.50303156 -0.13101251  0.86823839  0.91687792  0.51184089  0.85632289\n",
      "  0.85037308 -0.34628776 -0.75959532 -0.08915292 -0.76708311  0.35125714\n",
      " -0.05783649  0.31488427 -0.55765016  0.09960998 -0.28447571 -0.5199629\n",
      " -0.95278809  0.14050903  0.4461748  -0.65816572 -0.39111112 -0.03345238\n",
      "  0.2124354   0.59594976  0.01985456  0.87135934  0.5620336   0.13204183\n",
      " -0.19103881 -0.82796028  0.0332427   0.04661707 -0.84994989  0.57356454\n",
      "  0.57816937 -0.55477485 -0.34394103 -0.23189319 -0.58176232 -0.54245204\n",
      " -0.42417861  0.29754119 -0.26856489 -0.31930613 -0.81220313  0.98508699\n",
      " -0.28556335 -0.86237451 -0.61803336 -0.6982543  -0.79549434 -0.97006027\n",
      "  0.37228052 -0.95546938 -0.99671037 -0.39109451 -0.05608396 -0.04507536\n",
      "  0.74798618 -0.99632803 -0.53174934 -0.75950896 -0.47025991  0.07135111\n",
      "  0.47089883 -0.64360716  0.27926669 -0.12797994  0.83948424  0.74297743\n",
      " -0.17191338 -0.50924443  0.74567871 -0.6012015   0.56260347  0.77619982\n",
      " -0.40910031  0.96267075  0.22213927 -0.34480764 -0.34099042  0.84468201\n",
      "  0.39183275  0.98300793  0.62075017 -0.86497113 -0.86430159  0.5072518\n",
      "  0.63280201 -0.87623575  0.75305393 -0.60182645  0.23631865 -0.12030342\n",
      " -0.08743135 -0.81590305  0.28933636 -0.65326503 -0.90398874  0.31029762\n",
      " -0.2100272   0.79026291  0.42674534  0.322647   -0.94336154  0.93006848\n",
      "  0.94202005  0.52679757 -0.90493217  0.43670382 -0.91492869  0.69911172\n",
      "  0.60150462  0.18306112 -0.66449688  0.23443337  0.03962781 -0.73677419\n",
      " -0.4036578   0.01322582  0.74142637 -0.92720868 -0.60751436 -0.99275202\n",
      "  0.31896257 -0.81827966 -0.71912961  0.52224054  0.83871172 -0.37239634\n",
      " -0.34015476 -0.2787655   0.3254874   0.54346825 -0.01360784 -0.27909211\n",
      "  0.18646393  0.54448121 -0.26382292  0.73868903 -0.9961912   0.35136877\n",
      " -0.4099862  -0.74406044  0.96472951  0.44403924  0.52315005  0.38830121\n",
      "  0.68038693 -0.60040382 -0.52507865 -0.62258676  0.71887931 -0.44909739\n",
      " -0.49562496 -0.07858918 -0.42747407  0.27779395  0.37091505  0.70509176\n",
      "  0.72280234 -0.59281695 -0.003842    0.8765171  -0.07158942  0.11246532\n",
      " -0.7849408  -0.90800154  0.34250269 -0.81937109 -0.93397957 -0.08972373\n",
      " -0.39634318  0.41633247 -0.00667627  0.12386995  0.75636878  0.54237875\n",
      "  0.77211854  0.54545243 -0.47983404 -0.2705039   0.37744957 -0.56042415\n",
      "  0.41394726 -0.42058089  0.73650691 -0.03331567 -0.49453549  0.8145222\n",
      " -0.34172846  0.19976476 -0.76420892  0.37614362  0.79906856  0.84291185\n",
      "  0.74233855 -0.55587417 -0.98474382  0.36732131 -0.14146767  0.50883542\n",
      " -0.31119691  0.91031312 -0.95920494 -0.67102586  0.91588411  0.28787095\n",
      " -0.41644124 -0.22384949 -0.40707433 -0.39007512  0.22717439 -0.05155284\n",
      " -0.99768617  0.4416833  -0.56058098 -0.6870793  -0.41732128 -0.62344948\n",
      " -0.18226825 -0.29340538  0.61777593  0.93066832 -0.97101595  0.94715611\n",
      "  0.86904346 -0.93364451  0.81289157  0.63567837  0.96387583 -0.9997931\n",
      "  0.8971901   0.9609266  -0.75340279 -0.32704968 -0.63808788 -0.43653226\n",
      "  0.57742168  0.30842087  0.95534754  0.52634353  0.88786774 -0.31085977\n",
      "  0.67935186 -0.24346197 -0.88957396  0.94965141 -0.69031126 -0.11043129\n",
      "  0.89102647  0.58903245 -0.52681449  0.7526103  -0.93376268 -0.51387721\n",
      "  0.05647558 -0.47040454  0.17576161 -0.81535355 -0.25662434 -0.09639539\n",
      " -0.83328241 -0.94774599 -0.97569639 -0.1298466  -0.21409645 -0.67187439\n",
      " -0.29259688  0.09722908  0.65721172  0.92621371 -0.06720432 -0.4741362\n",
      " -0.39150935 -0.20193331  0.41784272  0.9876316   0.41497729  0.84500505\n",
      " -0.78679335  0.25525075  0.71753297  0.37225389  0.89662761  0.42128149\n",
      " -0.9982875  -0.17354253 -0.80012214 -0.84356149  0.14691454  0.45070165\n",
      "  0.08986369  0.91813321 -0.05373613  0.04652392 -0.74792693  0.32187096\n",
      "  0.69583675 -0.42296205  0.98881787  0.12235621  0.29385466 -0.69932503\n",
      "  0.80790497 -0.1316498   0.7947558  -0.43180982 -0.45668712  0.53298382\n",
      "  0.22113985 -0.9461324  -0.13295975]\n",
      "\n",
      "The activity is: **LAYING**\n",
      "\n",
      "The reason for this prediction is that the data shows a relatively low level of activity, with most values being close to zero. This suggests that the person is not moving around much, which is consistent with the activity of laying down.\n",
      "\n",
      "**Data 2:**\n",
      "The data is:\n",
      "[ 9.31350632e-01  4.31331177e-01 -9.60281855e-01 -2.15775250e-01\n",
      " -2.16809414e-01 -1.98746756e-02  3.03025517e-01  7.67853772e-01\n",
      "  3.62365613e-01  8.92414401e-01  7.31769806e-01 -1.66461970e-01\n",
      " -3.54515234e-01  9.14464476e-01 -6.24791869e-01 -4.56314181e-01\n",
      "  7.49261270e-02  9.41331193e-01  6.34280096e-02 -7.30085241e-01\n",
      " -5.14363272e-01 -4.45952850e-01 -8.43762303e-01  2.86322191e-01\n",
      " -4.46023837e-01 -4.70777500e-01  3.92050681e-01  9.34355850e-01\n",
      "  4.53054212e-01 -5.72606815e-01 -8.47410242e-01  5.06677183e-01\n",
      "  5.30104703e-01  6.42322393e-01  4.37076088e-01 -3.84270808e-01\n",
      "  9.67137138e-01 -5.35717732e-01  8.51961845e-01  9.53383663e-01\n",
      " -4.19862084e-01  1.67124561e-01  3.24546285e-01 -4.96945428e-01\n",
      "  9.97025332e-01  6.96397214e-01  8.75658768e-01  3.78446290e-01\n",
      "  9.30171098e-01 -3.46857486e-01 -2.64967462e-01  4.07046964e-02\n",
      "  1.57836699e-01  9.73588451e-01  5.78551757e-01  9.74498207e-01\n",
      " -6.45127118e-01  2.65239508e-01  5.23710168e-01  5.57201632e-01\n",
      "  8.36694804e-01  2.12670975e-01 -5.23058323e-01  9.59036027e-01\n",
      "  1.40382094e-01  9.61222417e-01 -5.43769418e-01 -2.71679295e-01\n",
      "  5.13887167e-01 -3.33339828e-01 -4.50903162e-01  9.30757737e-01\n",
      " -1.98119033e-01 -7.95232945e-01 -3.85335296e-01 -6.43616705e-01\n",
      " -5.04016294e-01  1.78120743e-01 -4.02220632e-01 -8.59228588e-01\n",
      "  1.95305865e-01 -1.75199697e-01 -3.38365213e-01 -4.73476097e-01\n",
      "  6.04325444e-01 -2.63612113e-02  3.26595459e-01 -2.55626463e-01\n",
      "  6.12156904e-01 -4.64124663e-01 -1.57854453e-01  5.58785015e-01\n",
      " -2.29428283e-01 -4.57163856e-01 -3.55865743e-01  4.05639693e-01\n",
      " -2.36954492e-01  3.69225342e-01 -8.29006034e-01 -3.32506425e-01\n",
      "  1.31089031e-01  6.44894547e-01 -9.54370826e-01 -4.89367616e-01\n",
      "  1.61601604e-01 -3.97793848e-01 -5.55093507e-01 -6.50951386e-02\n",
      "  8.60353354e-01  6.90696048e-01 -9.35562641e-01 -1.98169314e-01\n",
      "  4.41525908e-01 -3.64132116e-01  2.53488557e-02  4.67464771e-01\n",
      "  5.75211708e-01  6.18007422e-01  1.88619623e-02 -4.62365001e-01\n",
      " -8.96593049e-01  1.53398336e-01 -5.20697237e-01  5.89128814e-01\n",
      " -7.35632677e-01 -3.66155327e-01 -6.88417216e-01 -2.57000402e-01\n",
      "  5.54981512e-01  9.47125103e-01 -4.26287149e-01  7.24671261e-01\n",
      "  8.69376322e-01  6.64501568e-01  6.00585519e-02 -5.32637220e-01\n",
      " -2.30910490e-01  1.44669345e-01  8.30300530e-01 -7.74327681e-01\n",
      " -2.27006252e-01  1.52746124e-01  4.22358823e-01 -1.34299317e-01\n",
      "  8.76033440e-01  3.77424521e-01 -6.12132287e-02 -9.13225403e-01\n",
      "  1.92529638e-01  5.53771865e-01  3.39220984e-01  3.88399833e-01\n",
      "  8.80496686e-01  9.78818977e-01 -9.18733073e-01 -9.33703573e-01\n",
      "  1.59404219e-02 -8.91672480e-01 -2.34515721e-01 -6.69445203e-01\n",
      "  5.80398065e-01  3.20883639e-01  3.44593794e-02 -2.99873416e-01\n",
      "  6.64676927e-01  1.68145969e-01 -4.44930587e-01  7.27582308e-01\n",
      " -7.01710060e-01  3.88291258e-01 -7.38346238e-01  2.50479589e-01\n",
      " -5.06309604e-01  7.01018689e-01 -9.03497899e-01  3.33964021e-01\n",
      "  9.24722401e-01  2.18362699e-01  3.34611819e-01 -5.33260066e-01\n",
      " -3.85095242e-01 -4.79886211e-01 -4.19301742e-01  6.30635100e-01\n",
      "  5.94684204e-01  6.22241772e-01  6.48977678e-01  1.43239250e-01\n",
      "  4.73312531e-01  6.90531342e-01 -5.71915297e-02  8.58445020e-01\n",
      " -1.66382335e-01  4.84068260e-01 -6.88862753e-01 -3.74515772e-02\n",
      " -7.90348064e-01  7.77475593e-02  1.64195274e-01  4.54400385e-01\n",
      " -6.88347867e-01  3.22977750e-01  9.61124635e-02 -1.24662390e-01\n",
      " -4.01178128e-01 -3.97476360e-01  5.11584502e-01 -2.44719909e-02\n",
      " -2.18849568e-01 -8.21761539e-01  6.74152380e-01  6.94046478e-02\n",
      " -5.81884457e-01 -1.93335388e-01 -5.15450922e-01  5.22977790e-01\n",
      "  3.32332463e-01 -1.85371266e-03  2.21734568e-01 -1.10523488e-01\n",
      " -5.68072685e-01  9.21422818e-01  5.54550749e-01  2.32256643e-01\n",
      "  7.97794682e-01 -9.04471453e-01 -7.17600045e-01  6.90446470e-03\n",
      " -1.22988187e-02  1.65967499e-01 -2.45151750e-01  1.59552879e-01\n",
      "  1.68345448e-01 -5.07696281e-01 -1.15229295e-02  7.44121776e-01\n",
      " -5.16444320e-01  2.28539702e-01 -5.71737355e-02 -1.89228561e-01\n",
      " -5.61026788e-01  3.17398380e-01  4.78260860e-01 -8.57213616e-01\n",
      " -7.93479932e-01  8.71527380e-01  4.04210460e-01  2.52836896e-01\n",
      " -7.26662936e-01  7.71085207e-01  4.28120904e-01 -8.20478345e-01\n",
      "  6.55257624e-01 -5.69268162e-01  6.86867652e-01  6.69722086e-01\n",
      " -9.84428897e-01 -5.00067961e-01  3.53348091e-02  1.39606681e-02\n",
      " -6.74345315e-01 -8.42281725e-01  5.13458273e-01  5.77393115e-01\n",
      " -5.46001943e-01 -2.02036840e-01 -7.17018834e-01 -3.88112740e-01\n",
      " -8.83628774e-01 -5.84193859e-01  4.89736585e-01  4.28101865e-01\n",
      "  8.40747553e-01 -8.94080458e-02 -5.59861745e-01  4.70540811e-01\n",
      " -2.81965245e-01  1.72322344e-01 -7.09034527e-01  9.81193134e-01\n",
      "  7.73887693e-01 -2.13275969e-01 -6.18049405e-01 -8.62462746e-01\n",
      "  3.30077800e-01  8.49074148e-01  2.74826918e-01 -5.39218297e-02\n",
      " -9.90035883e-01  4.96519359e-01  3.42584955e-01 -6.36965157e-01\n",
      "  3.64732506e-02 -7.94495698e-01 -3.01006233e-01  5.82379709e-01\n",
      "  9.50744648e-01  5.26400301e-01  1.66367006e-01 -1.15223374e-01\n",
      "  7.16996291e-01 -1.37796741e-01 -2.35317922e-01 -5.95329309e-01\n",
      "  9.72413955e-01  6.40101652e-02  3.61016922e-01  5.51664312e-01\n",
      " -7.73634846e-01  8.60120294e-01  3.05625945e-01 -7.88860110e-01\n",
      "  3.33351876e-01 -8.09330805e-02 -3.60008909e-01 -1.16893764e-01\n",
      "  9.53209007e-01 -6.62467472e-01  3.82068150e-01 -6.55985639e-01\n",
      " -7.70911913e-01 -7.99158247e-01  3.72184532e-01 -9.55040056e-01\n",
      "  9.07808489e-01  9.63027064e-01  1.06562995e-01  2.06645236e-01\n",
      "  7.23988979e-01  1.95420656e-02 -2.77985571e-01  6.12539931e-01\n",
      " -5.85608888e-01 -7.55250553e-01 -7.06715396e-01 -6.31093745e-01\n",
      "  7.32446538e-01  3.65070522e-01  1.02029916e-01  5.55179803e-01\n",
      "  6.36990521e-01  3.03568719e-01 -7.75581758e-01  9.71907984e-01\n",
      " -1.57267198e-01 -2.75277118e-01  1.38479366e-01  2.86736373e-01\n",
      "  6.84270513e-01 -3.05422599e-01 -3.07303744e-01  6.93889345e-01\n",
      "  9.19381965e-01  5.34393231e-01 -9.27981523e-01 -3.89388783e-01\n",
      "  9.30756322e-01 -6.17453395e-01 -1.51622322e-01 -5.28188422e-02\n",
      " -2.67799086e-01  8.09744700e-01 -2.97389677e-01 -4.77606303e-01\n",
      " -9.66346234e-01 -6.06551185e-01 -5.01148800e-01 -9.09399443e-01\n",
      "  5.54174370e-01 -4.13531397e-01 -8.32773206e-01 -7.28441222e-01\n",
      "  9.40422563e-01  4.92417635e-01  7.84938544e-01  6.52789365e-01\n",
      "  5.21068805e-01  9.64815200e-01  9.52940170e-02  3.15810799e-01\n",
      " -4.03497924e-01 -2.02134682e-01  1.05959374e-01  1.08511737e-01\n",
      "  5.55910493e-01  6.22898821e-01 -3.48702730e-01  8.94716433e-01\n",
      "  7.79761004e-01  4.94749911e-01  8.10731517e-01 -9.73842902e-02\n",
      " -3.76937542e-01 -1.52022478e-01  3.82356902e-01 -3.24943098e-02\n",
      "  2.32861112e-01 -6.97702846e-01 -4.54811317e-01  8.49380390e-01\n",
      " -4.05041933e-01 -8.72171324e-01  4.07558616e-01 -8.37315512e-02\n",
      "  7.01371878e-01 -8.28659116e-01  4.52358314e-01  3.36324691e-01\n",
      " -6.32765826e-01 -8.20672323e-01 -6.62317973e-01 -2.98584678e-01\n",
      " -8.17022259e-01 -7.03747440e-01 -9.64659717e-03  5.35112999e-01\n",
      "  2.78050327e-02  4.04976420e-01 -6.53033184e-01 -2.14840691e-02\n",
      " -5.16864727e-01 -4.46588986e-02 -7.30230620e-01 -2.01913769e-01\n",
      " -4.54346476e-01 -4.\n",
      "\n",
      " Answer from llama3.1-70b: \n",
      "Based on the given data, I will analyze each sample and predict the activity label.\n",
      "\n",
      "1. The first sample has a high value of tBodyAcc-mean()-X (0.59123672) and tBodyAcc-mean()-Y (0.35350348), indicating a significant acceleration in the X and Y axes. The tBodyAcc-std()-X (0.74054349) and tBodyAcc-std()-Y (0.07768547) values are also high, indicating a high standard deviation in the X and Y axes. This suggests that the person is moving their body in the X and Y axes with a high acceleration and high variability. The tBodyGyro-mean()-X (0.28271208) and tBodyGyro-mean()-Y (0.50726997) values are also high, indicating a significant rotation in the X and Y axes. Based on these features, I predict that the activity label is 'WALKING'.\n",
      "\n",
      "2. The second sample has a high value of tBodyAcc-mean()-X (9.31350632e-01) and tBodyAcc-mean()-Y (4.31331177e-01), indicating a significant acceleration in the X and Y axes. The tBodyAcc-std()-X (9.60281855e-01) and tBodyAcc-std()-Y (2.15775250e-01) values are also high, indicating a high standard deviation in the X and Y axes. This suggests that the person is moving their body in the X and Y axes with a high acceleration and high variability. The tBodyGyro-mean()-X (3.92050681e-01) and tBodyGyro-mean()-Y (9.34355850e-01) values are also high, indicating a significant rotation in the X and Y axes. Based on these features, I predict that the activity label is 'WALKING'.\n",
      "\n",
      "3. The third sample has a high value of tBodyAcc-mean()-X (-3.19188690e-01) and tBodyAcc-mean()-Y (1.32745782e-02), indicating a significant acceleration in the X axis. The tBodyAcc-std()-X (9.27840860e-01) and tBodyAcc-std()-Y (8.69016622e-01) values are also high, indicating a high standard deviation in the X and Y axes. This suggests that the person is moving their body in the X axis with a high acceleration and high variability. The tBodyGyro-mean()-X (6.51584257e-01) and tBodyGyro-mean()-Y (5.06661678e-01) values are also high, indicating a significant rotation in the X and Y axes. Based on these features, I predict that the activity label is 'WALKING'.\n",
      "\n",
      "4. The fourth sample has a high value of tBodyAcc-mean()-X (0.01443823) and tBodyAcc-mean()-Y (-0.70483746), indicating a significant acceleration in the Y axis. The tBodyAcc-std()-X (0.8294153) and tBodyAcc-std()-Y (-0.80527399) values are also high, indicating a high standard deviation in the X and Y axes. This suggests that the person is moving their body in the Y axis with a high acceleration and high variability. The tBodyGyro-mean()-X (0.4396371) and tBodyGyro-mean()-Y (0.58575954) values are also high, indicating a significant rotation in the X and Y axes. Based on these features, I predict that the activity label is 'WALKING'.\n",
      "\n",
      "However, considering the values of tBodyAcc-mean()-Z and tBodyGyro-mean()-Z, I would revise my prediction for the fourth sample to 'WALKING_UPSTAIRS' or 'WALKING_DOWNSTAIRS', as the values suggest a significant movement in the Z axis. \n",
      "\n",
      "In conclusion, the predicted activity labels are:\n",
      "\n",
      "1. 'WALKING'\n",
      "2. 'WALKING'\n",
      "3. 'WALKING'\n",
      "4. 'WALKING_UPSTAIRS' or 'WALKING_DOWNSTAIRS'\n"
     ]
    }
   ],
   "source": [
    "random_data = 2 * np.random.rand(4, 561) - 1\n",
    "test_rows_string = [np.array2string(random_data[0]), np.array2string(random_data[1]), np.array2string(random_data[2]), np.array2string(random_data[3])]\n",
    "\n",
    "query = f\"\"\"\n",
    "* You are a activity recognition model. \n",
    "* Your task is to analyze the given data in form of certain features and classify the activity as 'LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS' or 'WALKING_UPSTAIRS'. \n",
    "* The data is normalized between [-1, 1]\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "* The complete list of features is as follows:\n",
    "{features_string}\n",
    "\n",
    "\n",
    "Analyze the following data and predict the activities:\n",
    "1. {test_rows_string[0]}\n",
    "2. {test_rows_string[1]}\n",
    "3. {test_rows_string[2]}\n",
    "4. {test_rows_string[3]}\n",
    "\"\"\" \n",
    "\n",
    "model_name = \"llama3.1-8b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"Answer from llama3.1-8b: \")\n",
    "print(answer.content)\n",
    "\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"\\n Answer from llama3.1-70b: \")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from llama3.1-8b: \n",
      "Based on the provided data, I will analyze the activities and predict the activity labels.\n",
      "\n",
      "**Data Analysis**\n",
      "\n",
      "The data consists of 4 samples, each with 57 features. The features are normalized between [-1, 1].\n",
      "\n",
      "**Sample 1**\n",
      "\n",
      "The first sample has the following features:\n",
      "\n",
      "[ 4.67549950e-01  5.61899778e-01 -2.71289076e-02  5.46914863e-01\n",
      " -2.45753590e-01  2.29554869e-01  4.06716427e-01  8.23122245e-02\n",
      " -9.31387187e-01  5.43764145e-01  5.05980141e-01 -8.19012118e-01\n",
      "  9.27773940e-01  4.27866485e-01 -6.82776227e-01 -3.94272035e-01\n",
      "  5.36000781e-01 -7.43886822e-01  6.65786241e-01 -3.69816089e-01\n",
      "  9.61358382e-01  2.06597684e-01  1.66911367e-01 -2.34754597e-01\n",
      "  8.44517158e-01  9.04722565e-01  7.69189193e-01  7.95653240e-01\n",
      " -8.20903503e-01  7.67519603e-01 -6.36039072e-01  9.68452488e-01\n",
      "  9.91518770e-02  9.46017471e-01 -4.16473075e-01 -4.38125188e-01\n",
      " -4.32167882e-01 -6.42348029e-01  7.08524493e-01  8.36620046e-01\n",
      " -8.50750221e-01 -9.05911910e-01  5.03728837e-01  1.05385282e-01\n",
      "  2.05490448e-01  6.39577618e-01  5.74370230e-01 -3.33563790e-01\n",
      "  4.77099039e-01 -1.14184669e-01  2.01862453e-01 -5.60346694e-02\n",
      " -1.44164702e-01  1.62653153e-01 -6.34589381e-01  4.99520863e-01\n",
      "  9.26446405e-01  8.86602311e-01  5.13479059e-01  3.10104285e-02\n",
      "  9.67478388e-02 -5.94581063e-01  5.57588183e-01  3.63760846e-01\n",
      " -3.55588866e-01 -2.67195481e-01  4.30722559e-02 -4.91906066e-01\n",
      " -3.70099078e-01 -8.64533284e-01 -4.85952488e-01 -3.38577867e-01\n",
      "  3.36020691e-02 -1.75305239e-01 -8.42343963e-01 -3.42329306e-01\n",
      " -9.93341098e-01 -4.64658738e-01 -1.73360960e-01 -9.88994094e-03\n",
      "  1.95027780e-01 -9.87599983e-01 -4.98844548e-01  4.13536354e-01\n",
      " -4.84829287e-01  6.16014970e-01  2.95319845e-01  7.98514665e-02\n",
      " -7.09905031e-01  3.30491679e-01 -6.87377381e-01  6.24605050e-01\n",
      "  4.99525435e-01 -3.00617720e-01  2.04144053e-01 -5.50874974e-01\n",
      " -7.90756610e-01 -6.56454735e-01  2.37657790e-01 -7.20011304e-01\n",
      " -5.73140214e-01 -3.00571401e-01  8.92742702e-01 -8.12323792e-01\n",
      " -4.43592343e-02 -9.93579376e-01  3.76560422e-01  3.32468611e-01\n",
      " -9.08270244e-01 -3.89343909e-01  1.64953750e-02 -7.29380559e-01\n",
      "  8.62975375e-01  2.89324192e-01 -5.01648197e-01 -9.82126477e-01\n",
      " -7.71846394e-01 -7.40601173e-01  6.84168462e-01  4.56598082e-01\n",
      "  6.09214172e-01  2.63092272e-01 -3.75383456e-01 -9.30678230e-01\n",
      "  3.69205074e-01 -7.70434177e-01 -5.92597780e-01  3.53918647e-01\n",
      " -4.01508724e-01 -9.99374889e-01 -4.11950565e-01 -8.74348094e-01\n",
      " -1.96993396e-01 -2.37199412e-01 -3.37731769e-01  6.48836070e-01\n",
      "  9.38381290e-01 -5.84748526e-01  1.68730512e-01  3.37228582e-03\n",
      "  8.26344461e-01 -7.15476485e-01  5.66637025e-01 -5.75218611e-01\n",
      " -2.64411906e-01  8.07781921e-02  6.00304290e-01  6.33798035e-02\n",
      "  8.34411832e-01  4.55722782e-01 -7.00472055e-02 -7.01548735e-01\n",
      "  7.56712331e-01 -2.50318074e-01 -2.39517635e-01 -1.20048841e-01\n",
      "  8.47590569e-01  7.83050454e-01  8.67854532e-01 -6.10997965e-01\n",
      " -9.20474291e-01  1.15909068e-01  9.37802393e-01 -7.50443201e-01\n",
      "  2.13590257e-01 -1.86114663e-01  3.96187656e-01 -6.39056584e-01\n",
      "  5.34275443e-01 -6.99904376e-01  1.21622483e-01  5.39222367e-02\n",
      "  1.10139978e-01 -9.93432083e-01  6.06776148e-01  4.99496063e-01\n",
      " -9.56070892e-01  8.67637550e-01 -9.88461807e-01 -2.60846889e-01\n",
      "  8.82187485e-02  2.47013760e-02 -4.98535125e-01 -1.55991345e-01\n",
      "  9.32661709e-01  6.87712865e-02 -1.09516531e-01  4.80290060e-01\n",
      " -8.82139465e-01  8.97154291e-01 -9.03460176e-01  2.53307308e-01\n",
      "  3.91528941e-01  6.28876939e-01 -4.28267272e-01  4.94320694e-01\n",
      "  2.01440614e-01  4.70143837e-01  3.07628213e-01 -3.89234115e-01\n",
      "  6.56977927e-01  2.33279568e-01 -2.77452490e-02 -8.21973623e-01\n",
      " -9.82656556e-01 -9.98097364e-02 -2.45648016e-01  1.77002413e-01\n",
      "  9.39638373e-01 -5.35700621e-01  9.74295651e-02 -7.58923790e-01\n",
      " -9.16275784e-01 -9.02108042e-02 -5.72487402e-01  3.85278041e-01\n",
      "  3.58522769e-01  7.31764964e-01 -4.02480799e-01 -2.04365587e-01\n",
      "  7.81378901e-02 -6.61987914e-01  8.29916133e-01  8.37203323e-02\n",
      "  9.21814406e-01 -6.98389200e-01  4.93566610e-01  8.56135679e-01\n",
      "  6.41897818e-02 -8.92985167e-01  6.44517931e-01 -8.06231391e-01\n",
      "  4.05622176e-01 -7.73835988e-01  5.70193028e-01 -9.76562692e-01\n",
      "  6.09232044e-01  8.81020177e-01 -9.69343342e-01  9.45075611e-01\n",
      "  1.30336521e-01  1.56541823e-01  1.75088154e-01 -2.20256425e-01\n",
      "  9.27052431e-01 -4.63130798e-01 -1.43064159e-01  4.66231906e-01\n",
      " -8.57410036e-01 -1.01963201e-01 -1.29087513e-01  5.88949189e-02\n",
      "  4.65172701e-02 -9.45318659e-01 -5.80845705e-01 -4.40884850e-01\n",
      " -3.15780689e-01  6.57819142e-01 -8.52093766e-01 -7.82984459e-01\n",
      "  9.17785873e-01  7.68993961e-01  8.08117020e-01  5.67815864e-01\n",
      " -3.22851875e-01 -4.28464704e-01 -8.29737353e-01 -2.39909586e-01\n",
      " -1.83962297e-01 -3.77083443e-01 -4.27033811e-01 -9.20480543e-01\n",
      " -7.59086964e-01 -2.30058322e-01 -6.58667492e-01  7.10121569e-01\n",
      " -4.64573212e-01  4.57191751e-01  2.61216225e-01 -9.44086493e-01\n",
      "  1.54129281e-01 -4.33175091e-01 -8.07047974e-01  4.42292937e-01\n",
      "  9.46412436e-02  6.98734061e-01  3.61077676e-01  3.77768232e-01\n",
      "  2.23974999e-01  7.21791558e-01  6.88956401e-01  2.83096775e-02\n",
      " -6.06358554e-01  7.00916350e-01  6.64107641e-01 -9.30641347e-01\n",
      "  5.30505541e-01  5.51872597e-01 -7.72984097e-01  2.65168791e-01\n",
      " -6.97538093e-01  1.74759930e-01 -4.06174650e-01  4.82905733e-01\n",
      " -4.11775669e-01 -3.74608075e-01  8.57563241e-01  2.21248099e-01\n",
      "  5.35244543e-01 -8.93324346e-01  9.62707305e-01 -4.85209136e-01\n",
      "  9.93343815e-01  4.11129148e-01 -1.15170253e-01  8.55124080e-01\n",
      "  7.05650977e-01 -7.49866869e-01  6.25593629e-02  7.26976285e-01\n",
      " -5.86066728e-01 -7.94568671e-03  3.19223713e-01  9.63959391e-01\n",
      "  9.81309075e-01 -4.35658104e-01  4.66872355e-02 -6.60792719e-01\n",
      " -2.85470083e-01 -6.88736405e-01  9.50959684e-01 -6.25467288e-01\n",
      "  3.77280537e-02 -5.75755665e-01  6.65348222e-01 -8.09657084e-01\n",
      "  4.32221531e-01 -2.77416196e-01 -1.50568603e-01  4.59577263e-01\n",
      " -5.98576413e-01 -4.33757696e-01 -6.46286701e-01  7.65893426e-01\n",
      " -1.64477551e-01  3.06425889e-01 -5.42169662e-01  6.76264811e-01\n",
      "  1.01002957e-01  9.42335030e-01 -8.11595674e-01 -4.12404856e-01\n",
      " -4.58457706e-01 -2.75701561e-02  7.54838614e-02 -7.20553280e-02\n",
      " -6.62466324e-01  6.96665583e-01 -5.56130856e-02  6.08819072e-01\n",
      " -2.82672240e-01  4.47353160e-01 -5.62768915e-01 -1.82360976e-01\n",
      " -1.33082819e-02  2.39040340e-01 -7.00066313e-01  7.73944916e-01\n",
      " -6.71926922e-02 -4.58662721e-01  7.33327328e-01  8.93664011e-01\n",
      " -6.04016083e-01  8.08169557e-01 -8.74455848e-01 -8.02255153e-01\n",
      "  5.89761154e-01 -5.62627582e-01 -6.69563045e-01 -6.27294179e-01\n",
      "  7.89566111e-01 -6.40751718e-01 -3.36668063e-01 -7.03769928e-01\n",
      " -8.50305313e-01  9.70659329e-01 -9.80648926e-01 -5.09570869e-01\n",
      " -1.98997280e-01  4.72620821e-01  2.35009480e-01  3.32307546e-02\n",
      "  1.45953565e-01  6.28186907e-05 -7.35986548e-03  7.13213976e-01\n",
      "  7.83006170e-01 -6.21603594e-02 -9.45367598e-01 -8.08284415e-01\n",
      "  4.37109932e-01  2.21543891e-01  2.62965098e-01  2.49748127e-01\n",
      "  3.13885092e-01  8.41628158e-02 -5.57976257e-01  9.46725430e-01\n",
      " -9.28912842e-01 -5.61602349e-01 -6.34671688e-01  7.26831414e-01\n",
      " -8.63023164e-02 -8.92494088e-01  2.15183690e-01  3.46164914e-02\n",
      "  4.15646504e-01 -8.41498791e-01 -8.56413233e-01  7.92059299e-01\n",
      "  3.05267077e-01  7.65615128e-01  1.17529943e-01  9.26069286e-01\n",
      "  4.38394529e-01 -3.66282889e-01 -7.54240297e-01  9.79921598e-01\n",
      "  2.76785414e-01  3.78159922e-01 -6.77250420e-01  3.77133709e-01\n",
      "  7.81934500e-01  8.39294481e-01 -5.55538251e-01 -4.97018572e-01\n",
      " -6.30393883e-01  9.12805479e-02  2.48193088e-01  6.46351754e-01\n",
      "  4.00664090e-01 -9.81545072e-01 -2.82785634e-01 -5.72175861e-01\n",
      "  3.51875327e-01 -5.07055696e-01 -2.96398228e-01  2.12155810e-01\n",
      "  7.45001388e-01  6.75261061e-02 -9.25615263e-02  1.41390156e-01\n",
      " -5.47578641e-01 -6.04518668e-01  5.89225299e-01  5.21183698e-01\n",
      "  5.36522059e-01  3.75669566e-01 -7.41001231e-01  2.02031538e-01\n",
      "  8.99516184e-01 -9.95196586e-01 -1.26094554e-01  6.26834849e-02\n",
      " -7.43858585e-02  2.44579602e-01 -7.72308601e-01 -6.87167096e-01\n",
      "  9.37972946e-01  3.00601630e-01  1.98606536e-01  8.28108817e-01\n",
      " -4.33004105e-01  8.11887624e-01 -1.50311243e-01 -4.16536066e-01\n",
      " -3.76036646e-01  6.88523051e-01 -1.97156735e-01  2.02218434e-01\n",
      " -6.66411143e-01  7.53815308e-01  1.52877463e-01  8.02607406e-01\n",
      " -1.40229511e-01 -1.02087747e-01  2.73471414e-02 -4.33338696e-01\n",
      " -1.21185060e-01  4.50734847e-01  5.50529094e-01  1.20076630e-03\n",
      " -3.18799587e-01 -2.16528599e-01  8.94989507e-01 -9.75852005e-01\n",
      "  6.45461381e-01  9.44506475e-01 -4.80963637e-01  9.41394187e-01\n",
      " -1.93471084e-01 -1.01335036e-01  4.61541629e-01  9.33651957e-01\n",
      " -7.56407958e-01 -7.39263847e-01 -7.48243545e-01 -6.52155794e-01\n",
      "  7.73654616e-01 -6.54736492e-01  9.26448179e-01 -3.29149739e-01\n",
      "  4.34056069e-01  2.69033628e-01 -3.74586062e-01  3.66404020e-01\n",
      " -6.85885083e-01  7.74784532e-01  2.13323660e-01  8.64321223e-01\n",
      "  4.93969030e-01 -9.14738834e-01 -4.89416064e-01 -2.77041783e-01\n",
      "  1.38935057e-01  4.06290935e-01  3.77200051e-01  4.00985786e-01\n",
      " -2.20874813e-01 -2.12075140e-02 -9.88836406e-01 -5.37954302e-01\n",
      " -8.50668107e-01 -1.08879109e-01 -3.32490113e-01 -6.06678956e-01\n",
      " -4.69285086e-01  9.62690890e-01  3.19390405e-01 -6.76136425e-01\n",
      " -1.96264613e-01 -2.23326701e-01 -8.51918224e-02  8.28138064e-01\n",
      "  1.88035860e-01  4.41355077e-01 -3.31289444e-01 -2.08633402e-01\n",
      "  7.27924751e-01 -9.50832629e-01  1.89364630e-02 -4.53125543e-01\n",
      "  5.35066840e-01 -7.31244079e-01 -1.25366197e-01 -3.43555096e-01\n",
      " -9.82220432e-01  9.80111483e-01  1.56701274e-01 -2.01009446e-01\n",
      "  8.69845534e-01]\n",
      "\n",
      "**Activity Label Prediction**\n",
      "\n",
      "Based on the provided data, I predict the activity labels as follows:\n",
      "\n",
      "* Sample 1: SITTING\n",
      "* Sample 2: WALKING\n",
      "* Sample 3: WALKING_UPSTAIRS\n",
      "* Sample 4: WALKING_DOWNSTAIRS\n",
      "\n",
      "Note that the activity labels are predicted based on the features provided, and the accuracy of the prediction may vary depending on the quality of the data and the complexity of the activity recognition model.\n",
      "\n",
      " Answer from llama3.1-70b: \n",
      "Based on the given data, I predict the activities as follows:\n",
      "\n",
      "1. WALKING\n",
      "2. WALKING\n",
      "3. SITTING\n",
      "4. WALKING\n",
      "\n",
      "The reasoning behind these predictions is as follows:\n",
      "\n",
      "- The first data point has a high value of 4.67549950e-01 for the feature 'tBodyAcc-mean()-X', which is a characteristic of walking. The other features also have values that are consistent with walking.\n",
      "- The second data point has a high value of 7.54351498e-01 for the feature 'tBodyAcc-mean()-X', which is also a characteristic of walking. The other features also have values that are consistent with walking.\n",
      "- The third data point has a low value of 0.47429936 for the feature 'tBodyAcc-mean()-X', which is a characteristic of sitting. The other features also have values that are consistent with sitting.\n",
      "- The fourth data point has a high value of 0.54710626 for the feature 'tBodyAcc-mean()-X', which is a characteristic of walking. The other features also have values that are consistent with walking.\n",
      "\n",
      "Note that these predictions are based on a simple analysis of the data and may not be accurate in all cases. A more sophisticated machine learning model would be needed to make more accurate predictions.\n"
     ]
    }
   ],
   "source": [
    "features_row = 0\n",
    "with open('TestDataset_561.csv', 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    rows = list(reader)\n",
    "\n",
    "if features_row < len(rows):\n",
    "    row = rows[features_row][:-2]\n",
    "    features_string = ', '.join(row)\n",
    "else:\n",
    "    print(f\"Error in features reading\")\n",
    "\n",
    "#This data will be given as examples for the LLM to learn and give better predictions\n",
    "train_rows = [[10, 190], [730, 890], [1380, 1540], [1990, 2160], [2670, 2840], [2410, 3590]]\n",
    "train_labels = [\"STANDING\", \"SITTING\", \"LAYING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]\n",
    "train_string = \"\"\n",
    "for i in range(len(train_rows)):\n",
    "    with open('Dataset_561.csv', 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        rows = list(reader)\n",
    "    for rown in train_rows[i]:\n",
    "        if (rown < len(rows)):\n",
    "            row = rows[rown][:-2]\n",
    "            train_rown_string = ', '.join(row)\n",
    "            train_string = train_string + '\\n' + train_rown_string + ': ' + train_labels[i]\n",
    "        else:\n",
    "            print(\"Error in train row reading\")\n",
    "\n",
    "random_data = 2 * np.random.rand(4, 561) - 1\n",
    "test_rows_string = [np.array2string(random_data[0]), np.array2string(random_data[1]), np.array2string(random_data[2]), np.array2string(random_data[3])]\n",
    "\n",
    "query = f\"\"\"\n",
    "* You are a activity recognition model. \n",
    "* Your task is to analyze the given data in form of certain features and classify the activity as 'LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS' or 'WALKING_UPSTAIRS'. \n",
    "* The data is normalized between [-1, 1]\n",
    "* Provide the activity label and, if necessary, a brief explanation of your reasoning.\n",
    "* The complete list of features is as follows:\n",
    "{features_string}\n",
    "\n",
    "A few examples are as follows:\n",
    "{train_string}\n",
    "\n",
    "Analyze the following data and predict the activities:\n",
    "1. {test_rows_string[0]}\n",
    "2. {test_rows_string[1]}\n",
    "3. {test_rows_string[2]}\n",
    "4. {test_rows_string[3]}\n",
    "\"\"\" \n",
    "model_name = \"llama3.1-8b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"Answer from llama3.1-8b: \")\n",
    "print(answer.content)\n",
    "\n",
    "model_name = \"llama3.1-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(\"\\n Answer from llama3.1-70b: \")\n",
    "print(answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
